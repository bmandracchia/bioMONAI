{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A set of custom loss functions\n",
    "output-file: losses.html\n",
    "title: Loss functions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSELoss\n",
       "\n",
       ">      MSELoss (inp:Any, targ:Any)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L29){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSELoss\n",
       "\n",
       ">      MSELoss (inp:Any, targ:Any)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### L1Loss\n",
       "\n",
       ">      L1Loss (inp:Any, targ:Any)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### L1Loss\n",
       "\n",
       ">      L1Loss (inp:Any, targ:Any)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(L1Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### SSIMLoss\n",
       "\n",
       ">      SSIMLoss (spatial_dims:int, data_range:float=1.0,\n",
       ">                kernel_type:monai.metrics.regression.KernelType|str=gaussian,\n",
       ">                win_size:int|collections.abc.Sequence[int]=11,\n",
       ">                kernel_sigma:float|collections.abc.Sequence[float]=1.5,\n",
       ">                k1:float=0.01, k2:float=0.03,\n",
       ">                reduction:monai.utils.enums.LossReduction|str=mean)\n",
       "\n",
       "*Compute the loss function based on the Structural Similarity Index Measure (SSIM) Metric.\n",
       "\n",
       "For more info, visit\n",
       "    https://vicuesoft.com/glossary/term/ssim-ms-ssim/\n",
       "\n",
       "SSIM reference paper:\n",
       "    Wang, Zhou, et al. \"Image quality assessment: from error visibility to structural\n",
       "    similarity.\" IEEE transactions on image processing 13.4 (2004): 600-612.*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SSIMLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CombinedLoss\n",
       "\n",
       ">      CombinedLoss (spatial_dims=2, mse_weight=0.33, mae_weight=0.33)\n",
       "\n",
       "*losses combined*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L46){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CombinedLoss\n",
       "\n",
       ">      CombinedLoss (spatial_dims=2, mse_weight=0.33, mae_weight=0.33)\n",
       "\n",
       "*losses combined*"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CombinedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L59){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIMLoss\n",
       "\n",
       ">      MSSSIMLoss (spatial_dims=2, window_size:int=8, sigma:float=1.5,\n",
       ">                  reduction:str='mean', levels:int=3, weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L59){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIMLoss\n",
       "\n",
       ">      MSSSIMLoss (spatial_dims=2, window_size:int=8, sigma:float=1.5,\n",
       ">                  reduction:str='mean', levels:int=3, weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIMLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.9686, device='cuda:0') \n",
      "ssim:  tensor(0.9949, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "msssim_loss = MSSSIMLoss(levels=3)\n",
    "ssim_loss = SSIMLoss(2)\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target\n",
    "loss = msssim_loss(output, target)\n",
    "loss2 = ssim_loss(output,target)\n",
    "print(\"ms-ssim: \",loss, '\\nssim: ', loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML1Loss\n",
       "\n",
       ">      MSSSIML1Loss (spatial_dims=2, alpha:float=0.025, window_size:int=8,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L117){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML1Loss\n",
       "\n",
       ">      MSSSIML1Loss (spatial_dims=2, alpha:float=0.025, window_size:int=8,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIML1Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-ssim:  tensor(0.0250) \n",
      "ssim:  tensor(0.9955)\n"
     ]
    }
   ],
   "source": [
    "msssiml1_loss = MSSSIML1Loss(alpha=0.025, window_size=11, sigma=1.5, levels=3)\n",
    "input_image = torch.randn(4, 1, 128, 128)  # Batch of 4 grayscale images (1 channel)\n",
    "target_image = torch.randn(4, 1, 128, 128)\n",
    "\n",
    "# Compute MSSSIM + Gaussian-weighted L1 loss\n",
    "loss = msssiml1_loss(input_image, target_image)\n",
    "loss2 = ssim_loss(input_image, target_image)\n",
    "print(\"ms-ssim: \", loss, '\\nssim: ', loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L194){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML2Loss\n",
       "\n",
       ">      MSSSIML2Loss (spatial_dims=2, alpha:float=0.1, window_size:int=11,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L194){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSSIML2Loss\n",
       "\n",
       ">      MSSSIML2Loss (spatial_dims=2, alpha:float=0.1, window_size:int=11,\n",
       ">                    sigma:float=1.5, reduction:str='mean', levels:int=3,\n",
       ">                    weights=None)\n",
       "\n",
       "*Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool*"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MSSSIML2Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0956, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "msssim_l2_loss = MSSSIML2Loss()\n",
    "output = torch.rand(10, 3, 64, 64).cuda()  # Example output with even dimensions\n",
    "target = torch.rand(10, 3, 64, 64).cuda()  # Example target with even dimensions\n",
    "loss = msssim_l2_loss(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropy and Dice Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L269){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossEntropyLossFlat3D\n",
       "\n",
       ">      CrossEntropyLossFlat3D (*args, axis:int=-1, weight=None,\n",
       ">                              ignore_index=-100, reduction='mean',\n",
       ">                              flatten:bool=True, floatify:bool=False,\n",
       ">                              is_2d:bool=True)\n",
       "\n",
       "*Same as `nn.CrossEntropyLoss`, but flattens input and target for 3D inputs.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L269){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CrossEntropyLossFlat3D\n",
       "\n",
       ">      CrossEntropyLossFlat3D (*args, axis:int=-1, weight=None,\n",
       ">                              ignore_index=-100, reduction='mean',\n",
       ">                              flatten:bool=True, floatify:bool=False,\n",
       ">                              is_2d:bool=True)\n",
       "\n",
       "*Same as `nn.CrossEntropyLoss`, but flattens input and target for 3D inputs.*"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CrossEntropyLossFlat3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L285){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DiceLoss\n",
       "\n",
       ">      DiceLoss (smooth=1)\n",
       "\n",
       "*DiceLoss computes the Sørensen–Dice coefficient loss, which is often used \n",
       "for evaluating the performance of image segmentation algorithms.\n",
       "\n",
       "The Dice coefficient is a measure of overlap between two samples. It ranges \n",
       "from 0 (no overlap) to 1 (perfect overlap). The Dice loss is computed as \n",
       "1 - Dice coefficient, so it ranges from 1 (no overlap) to 0 (perfect overlap).\n",
       "\n",
       "Attributes:\n",
       "    smooth (float): A smoothing factor to avoid division by zero and ensure numerical stability.\n",
       "\n",
       "Methods:\n",
       "    forward(inputs, targets):\n",
       "        Computes the Dice loss between the predicted probabilities (inputs) \n",
       "        and the ground truth (targets).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L285){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DiceLoss\n",
       "\n",
       ">      DiceLoss (smooth=1)\n",
       "\n",
       "*DiceLoss computes the Sørensen–Dice coefficient loss, which is often used \n",
       "for evaluating the performance of image segmentation algorithms.\n",
       "\n",
       "The Dice coefficient is a measure of overlap between two samples. It ranges \n",
       "from 0 (no overlap) to 1 (perfect overlap). The Dice loss is computed as \n",
       "1 - Dice coefficient, so it ranges from 1 (no overlap) to 0 (perfect overlap).\n",
       "\n",
       "Attributes:\n",
       "    smooth (float): A smoothing factor to avoid division by zero and ensure numerical stability.\n",
       "\n",
       "Methods:\n",
       "    forward(inputs, targets):\n",
       "        Computes the Dice loss between the predicted probabilities (inputs) \n",
       "        and the ground truth (targets).*"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DiceLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# inputs and targets must be equally dimensional tensors\n",
    "from torch import randn, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Loss: 0.4982335567474365\n"
     ]
    }
   ],
   "source": [
    "inputs = randn((1, 1, 256, 256))  # Input\n",
    "targets = randint(0, 2, (1, 1, 256, 256)).float()  # Ground Truth\n",
    "\n",
    "# Initialize\n",
    "dice_loss = DiceLoss()\n",
    "\n",
    "# Compute loss\n",
    "loss = dice_loss(inputs, targets)\n",
    "print('Dice Loss:', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Ring Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L338){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FRCLoss\n",
       "\n",
       ">      FRCLoss (image1, image2)\n",
       "\n",
       "*Compute the Fourier Ring Correlation (FRC) loss between two images.\n",
       "\n",
       "#### Args:\n",
       "    - image1 (torch.Tensor): The first input image.\n",
       "    - image2 (torch.Tensor): The second input image.\n",
       "\n",
       "#### Returns:\n",
       "    - torch.Tensor: The FRC loss.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L338){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FRCLoss\n",
       "\n",
       ">      FRCLoss (image1, image2)\n",
       "\n",
       "*Compute the Fourier Ring Correlation (FRC) loss between two images.\n",
       "\n",
       "#### Args:\n",
       "    - image1 (torch.Tensor): The first input image.\n",
       "    - image2 (torch.Tensor): The second input image.\n",
       "\n",
       "#### Returns:\n",
       "    - torch.Tensor: The FRC loss.*"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(FRCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L355){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FCRCutoff\n",
       "\n",
       ">      FCRCutoff (image1, image2)\n",
       "\n",
       "*Calculate the cutoff frequency at when Fourier ring correlation drops to 1/7.\n",
       "\n",
       "#### Args:\n",
       "    - image1 (torch.Tensor): The first input image.\n",
       "    - image2 (torch.Tensor): The second input image.\n",
       "\n",
       "#### Returns:\n",
       "    - float: The cutoff frequency.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/bioMONAI/blob/main/bioMONAI/losses.py#L355){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FCRCutoff\n",
       "\n",
       ">      FCRCutoff (image1, image2)\n",
       "\n",
       "*Calculate the cutoff frequency at when Fourier ring correlation drops to 1/7.\n",
       "\n",
       "#### Args:\n",
       "    - image1 (torch.Tensor): The first input image.\n",
       "    - image2 (torch.Tensor): The second input image.\n",
       "\n",
       "#### Returns:\n",
       "    - float: The cutoff frequency.*"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(FCRCutoff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
