"""Event handlers"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/07_callbacks.ipynb.

# %% auto 0
__all__ = ['MeanLossGraphCallback']

# %% ../nbs/07_callbacks.ipynb 3
from fastai.callback.training import ShortEpochCallback, GradientAccumulation
from fastai.callback.tracker import  EarlyStoppingCallback, SaveModelCallback, ReduceLROnPlateau
from fastai.callback.schedule import ParamScheduler, SchedCos, SchedExp, SchedLin, SchedNo
from fastai.callback.core import Callback, range_of, Tensor
import matplotlib.pyplot as plt


# %% ../nbs/07_callbacks.ipynb 5
class MeanLossGraphCallback(Callback):
    "Update a graph of training and validation loss"
    order,run_valid=65,False

    def before_fit(self):
        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, "gather_preds")
        if not(self.run): return
        self.nb_batches = []
        self.train_losses = []
        assert hasattr(self.learn, 'progress')

    def after_train(self): 
        self.nb_batches.append(self.train_iter)

    def after_epoch(self):
        "Plot validation loss in the pbar graph"
        if not self.nb_batches: return
        rec = self.learn.recorder
        epochs = range(len(self.nb_batches)) + 1
        self.train_losses.append(rec.log[1])
        val_losses = [v[1] for v in rec.values]
        x_bounds = (0, self.n_epoch)
        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))
        self.progress.mbar.update_graph([(epochs, self.train_losses), (epochs, val_losses)], x_bounds, y_bounds)

