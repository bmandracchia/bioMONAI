{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification 2D\n",
    "\n",
    ">BloodMNIST Dataset Demo: This tutorial provides a comprehensive, step-by-step guide to using the bioMONAI platform for 2D microscopy image classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tutorial_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioMONAI.data import *\n",
    "from bioMONAI.transforms import *\n",
    "from bioMONAI.core import *\n",
    "from bioMONAI.core import Path\n",
    "from bioMONAI.data import get_image_files\n",
    "from bioMONAI.losses import *\n",
    "from bioMONAI.metrics import *\n",
    "from bioMONAI.datasets import download_medmnist\n",
    "\n",
    "from fastai.vision.all import CategoryBlock, GrandparentSplitter, parent_label, resnet34, CrossEntropyLossFlat, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Information and Download\n",
    "\n",
    "We'll employ the publicly available BloodMNIST dataset. The BloodMNIST is based on a dataset of individual normal cells, captured from individuals without infection, hematologic or oncologic disease and free of any pharmacologic treatment at the moment of blood collection. It contains a total of 17,092 images and is organized into 8 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> In this step, we will download the BloodMNIST dataset using the `download_medmnist` function from bioMONAI. This function will download the dataset and provide information about it. The dataset will be stored in the specified path. You can customize the path or dataset name as needed. Additionally, you can explore other datasets available in the MedMNIST collection by changing the dataset name in the `download_medmnist` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('../_data/medmnist_data/')\n",
    "info = download_medmnist('bloodmnist', image_path, download_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoader\n",
    "\n",
    "In this step, we will customize the DataLoader for the BloodMNIST dataset. The DataLoader is responsible for loading the data during training and validation. We will define the data loading strategy using the `BioDataLoaders.from_source()` method, configured with the arguments specified in `data_ops`. You can customize the following parameters to suit your needs:\n",
    "\n",
    "- `batch_size`: The number of samples per batch. Adjust this based on your GPU memory capacity.\n",
    "- `item_tfms`: List of item-level transformations to apply to the images. You can add or modify transformations to augment your dataset.\n",
    "- `splitter`: The method to split the dataset into training and validation sets. You can customize the split strategy if needed.\n",
    "\n",
    ">Feel free to experiment with different configurations to improve model performance or adapt to different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "path = image_path/'bloodmnist'\n",
    "train_path = path/'train'\n",
    "val_path = path/'val'\n",
    "\n",
    "data_ops = {\n",
    "    'blocks':       (BioImageBlock(cls=BioImageMulti), CategoryBlock(info['label'])),            # define a `TransformBlock` tailored for bioimaging data\n",
    "    'get_items':    get_image_files,                                                             # get image files in path\n",
    "    'get_y':        parent_label,                                                                # Label item with the parent folder name\n",
    "    'splitter':     GrandparentSplitter(train_name='train', valid_name='val'),                   # split data with the grandparent folder name\n",
    "    'item_tfms':    [ScaleIntensity(min=0.0, max=1.0), RandRot90(prob=0.5), RandFlip(prob=0.5)], # list of item transforms\n",
    "    'bs':           batch_size,                                                                  # batch size\n",
    "}\n",
    "\n",
    "data = BioDataLoaders.from_source(\n",
    "    path,                           # root directory for data\n",
    "    show_summary=False,             # print summary of the data\n",
    "    **data_ops,                     # rest of method arguments\n",
    "    )\n",
    "\n",
    "# print length of training and validation datasets\n",
    "print('train images:', len(data.train_ds.items), '\\nvalidation images:', len(data.valid_ds.items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Images\n",
    "\n",
    "In this step, we will visualize a batch of images from the BloodMNIST dataset using the `show_batch` method. This will help us understand the data distribution and verify the transformations applied to the images. The `max_n` parameter specifies the number of images to display.\n",
    "\n",
    "> - You can adjust the `max_n` parameter to display more or fewer images.\n",
    "> - Experiment with different transformations in the `item_tfms` list to see their effects on the images.\n",
    "> - Use the `show_batch` method at different stages of your data pipeline to ensure the data is being processed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "In this step, we will train the model using the `visionTrainer` class. The `fine_tune` method will be used to fine-tune the model for a specified number of epochs. The `freeze_epochs` parameter allows you to freeze the initial layers of the model for a certain number of epochs before unfreezing and training the entire model.\n",
    "\n",
    "> - You can adjust the `epochs` parameter to train the model for more or fewer epochs based on your dataset and computational resources.\n",
    "> - Experiment with different values for `freeze_epochs` to see how it affects model performance.\n",
    "> - Monitor the training process and adjust the learning rate or other hyperparameters if needed.\n",
    "> - Consider using techniques like early stopping or learning rate scheduling to improve training efficiency and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VisionTrainer Class\n",
    "\n",
    "The `visionTrainer` class is a high-level API designed to simplify the training process for vision models. It provides a convenient interface for training, fine-tuning, and evaluating deep learning models. Here are some key features and functionalities of the `visionTrainer` class:\n",
    "\n",
    "- **Initialization**: The class is initialized with the data, model architecture, loss function, and metrics. It also provides options to display a summary of the model and data.\n",
    "- **Fine-tuning**: The `fine_tune` method allows you to fine-tune the model for a specified number of epochs. You can freeze the initial layers of the model for a certain number of epochs before unfreezing and training the entire model.\n",
    "- **Training**: The class handles the training loop, including forward and backward passes, loss computation, and optimization.\n",
    "- **Evaluation**: The class provides methods to evaluate the model on validation and test datasets, compute metrics, and visualize results.\n",
    "- **Customization**: You can customize various aspects of the training process, such as learning rate, batch size, and data augmentations, to suit your specific needs.\n",
    "\n",
    "> The `visionTrainer` class is designed to streamline the training process, making it easier to experiment with different models and hyperparameters. It is particularly useful for tasks like image classification, where you can leverage pre-trained models and fine-tune them on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34\n",
    "\n",
    "loss = CrossEntropyLossFlat()\n",
    "metrics = accuracy\n",
    "\n",
    "trainer = visionTrainer(data, model, loss_fn=loss, metrics=metrics, show_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fine_tune(20, freeze_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on Validation Data\n",
    "\n",
    "In this step, we will evaluate the trained model on the validation dataset using the `evaluate_classification_model` function. This function computes the specified metrics and provides insights into the model's performance. Additionally, it can display the most confused classes to help identify areas for improvement.\n",
    "\n",
    "> - You can customize the `metrics` parameter to include other evaluation metrics relevant to your task.\n",
    "> - The `most_confused_n` parameter specifies the number of most confused classes to display. Adjust this value to see more or fewer confused classes.\n",
    "> - Set the `show_graph` parameter to `True` to visualize the confusion matrix and other evaluation graphs.\n",
    "> - Use this evaluation step to monitor the model's performance and make necessary adjustments to the training process or data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_model(trainer,  metrics=metrics, most_confused_n=5, show_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "\n",
    "In this step, we will save the trained model using the `save` method of the `visionTrainer` class. Saving the model allows us to reuse it later without retraining. This is particularly useful when you want to deploy the model or continue training at a later time.\n",
    "\n",
    "> - You can specify the file path and name for the saved model. Ensure the directory exists or create it if necessary.\n",
    "> - Consider saving the model at different checkpoints during training to have backups and the ability to revert to a previous state if needed.\n",
    "> - You can also save additional information such as the training history, optimizer state, and hyperparameters to facilitate future use or further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save('tmp-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on Test Data\n",
    "\n",
    "In this step, we will evaluate the trained model on the test dataset to assess its performance on unseen data. This is a crucial step to ensure that the model generalizes well and performs accurately on new, unseen samples. We will use the `evaluate_classification_model` function to compute the specified metrics and gain insights into the model's performance.\n",
    "\n",
    "> - Ensure that the test dataset is completely separate from the training and validation datasets to get an unbiased evaluation.\n",
    "> - You can customize the `metrics` parameter to include other evaluation metrics relevant to your task.\n",
    "> - The `show_graph` parameter can be set to `True` to visualize the confusion matrix and other evaluation graphs.\n",
    "> - Use this evaluation step to identify any potential issues with the model and make necessary adjustments to the training process or data pipeline.\n",
    "> - Consider experimenting with different model architectures, hyperparameters, and data augmentations to further improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = path/'test'\n",
    "\n",
    "test_data = data.test_dl(get_image_files(test_path).shuffle(), with_labels=True)\n",
    "# print length of test dataset\n",
    "print('test images:', len(test_data.items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification_model(trainer, test_data, metrics=metrics, show_graph=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model\n",
    "\n",
    "In this step, we will load the previously trained model using the `load` method of the `visionTrainer` class. In this example, we will:\n",
    "\n",
    "> - Create a trainer instance and load the previously saved model.\n",
    "> - Fine tune the model a several epochs more.\n",
    "> - Evaluate the model with test data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34\n",
    "\n",
    "loss = CrossEntropyLossFlat()\n",
    "metrics = accuracy\n",
    "\n",
    "trainer2 = visionTrainer(data, model, loss_fn=loss, metrics=metrics, show_summary=False)\n",
    "\n",
    "# Load saved model\n",
    "trainer2.load('tmp-model')\n",
    "\n",
    "# Train several additional epochs\n",
    "trainer2.fine_tune(5, freeze_epochs=1)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "evaluate_classification_model(trainer2, test_data, metrics=metrics, show_graph=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
