{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "> Event handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.callback.training import ShortEpochCallback, GradientAccumulation\n",
    "from fastai.callback.tracker import  EarlyStoppingCallback, SaveModelCallback, ReduceLROnPlateau\n",
    "from fastai.callback.schedule import ParamScheduler, SchedCos, SchedExp, SchedLin, SchedNo\n",
    "from fastai.callback.core import Callback, range_of, Tensor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks\n",
    "\n",
    "Callbacks that add functionlities during the training phase, including Callbacks that make decisions depending how a monitored metric/loss behaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MeanLossGraphCallback(Callback):\n",
    "    \"Update a graph of training and validation loss\"\n",
    "    order,run_valid=65,False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, \"gather_preds\")\n",
    "        if not(self.run): return\n",
    "        self.nb_batches = []\n",
    "        self.train_losses = []\n",
    "        assert hasattr(self.learn, 'progress')\n",
    "\n",
    "    def after_train(self): \n",
    "        self.nb_batches.append(self.train_iter)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Plot validation loss in the pbar graph\"\n",
    "        if not self.nb_batches: return\n",
    "        rec = self.learn.recorder\n",
    "        epochs = range(len(self.nb_batches)) + 1\n",
    "        self.train_losses.append(rec.log[1])\n",
    "        val_losses = [v[1] for v in rec.values]\n",
    "        x_bounds = (0, self.n_epoch)\n",
    "        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))\n",
    "        self.progress.mbar.update_graph([(epochs, self.train_losses), (epochs, val_losses)], x_bounds, y_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ShortEpochCallback\n",
       "\n",
       ">      ShortEpochCallback (pct=0.01, short_valid=True)\n",
       "\n",
       "Fit just `pct` of an epoch, then stop"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ShortEpochCallback\n",
       "\n",
       ">      ShortEpochCallback (pct=0.01, short_valid=True)\n",
       "\n",
       "Fit just `pct` of an epoch, then stop"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ShortEpochCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GradientAccumulation\n",
       "\n",
       ">      GradientAccumulation (n_acc=32)\n",
       "\n",
       "Accumulate gradients before updating weights"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GradientAccumulation\n",
       "\n",
       ">      GradientAccumulation (n_acc=32)\n",
       "\n",
       "Accumulate gradients before updating weights"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GradientAccumulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EarlyStoppingCallback\n",
       "\n",
       ">      EarlyStoppingCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                             patience=1, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that terminates training when monitored quantity stops improving.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### EarlyStoppingCallback\n",
       "\n",
       ">      EarlyStoppingCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                             patience=1, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that terminates training when monitored quantity stops improving.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(EarlyStoppingCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SaveModelCallback\n",
       "\n",
       ">      SaveModelCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         fname='model', every_epoch=False, at_end=False,\n",
       ">                         with_opt=False, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that saves the model's best during training and loads it at the end.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| fname | str | model | model name to be used when saving model. |\n",
       "| every_epoch | bool | False | if true, save model after every epoch; else save only when model is better than existing best. |\n",
       "| at_end | bool | False | if true, save model when training ends; else load best model if there is only one saved model. |\n",
       "| with_opt | bool | False | if true, save optimizer state (if any available) when saving model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SaveModelCallback\n",
       "\n",
       ">      SaveModelCallback (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         fname='model', every_epoch=False, at_end=False,\n",
       ">                         with_opt=False, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that saves the model's best during training and loads it at the end.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| fname | str | model | model name to be used when saving model. |\n",
       "| every_epoch | bool | False | if true, save model after every epoch; else save only when model is better than existing best. |\n",
       "| at_end | bool | False | if true, save model when training ends; else load best model if there is only one saved model. |\n",
       "| with_opt | bool | False | if true, save optimizer state (if any available) when saving model. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SaveModelCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ReduceLROnPlateau\n",
       "\n",
       ">      ReduceLROnPlateau (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         patience=1, factor=10.0, min_lr=0, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that reduces learning rate when a metric has stopped improving.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| factor | float | 10.0 | the denominator to divide the learning rate by, when reducing the learning rate. |\n",
       "| min_lr | int | 0 | the minimum learning rate allowed; learning rate cannot be reduced below this minimum. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/tracker.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ReduceLROnPlateau\n",
       "\n",
       ">      ReduceLROnPlateau (monitor='valid_loss', comp=None, min_delta=0.0,\n",
       ">                         patience=1, factor=10.0, min_lr=0, reset_on_fit=True)\n",
       "\n",
       "A `TrackerCallback` that reduces learning rate when a metric has stopped improving.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| monitor | str | valid_loss | value (usually loss or metric) being monitored. |\n",
       "| comp | NoneType | None | numpy comparison operator; np.less if monitor is loss, np.greater if monitor is metric. |\n",
       "| min_delta | float | 0.0 | minimum delta between the last monitor value and the best monitor value. |\n",
       "| patience | int | 1 | number of epochs to wait when training has not improved model. |\n",
       "| factor | float | 10.0 | the denominator to divide the learning rate by, when reducing the learning rate. |\n",
       "| min_lr | int | 0 | the minimum learning rate allowed; learning rate cannot be reduced below this minimum. |\n",
       "| reset_on_fit | bool | True | before model fitting, reset value being monitored to -infinity (if monitor is metric) or +infinity (if monitor is loss). |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedulers\n",
    "\n",
    "Callback and helper functions to schedule hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParamScheduler\n",
       "\n",
       ">      ParamScheduler (scheds)\n",
       "\n",
       "Schedule hyper-parameters according to `scheds`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ParamScheduler\n",
       "\n",
       ">      ParamScheduler (scheds)\n",
       "\n",
       "Schedule hyper-parameters according to `scheds`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ParamScheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scheds` is a dictionary with one key for each hyper-parameter you want to schedule, with either a scheduler or a list of schedulers as values (in the second case, the list must have the same length as the the number of parameters groups of the optimizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedCos\n",
       "\n",
       ">      SchedCos (start, end)\n",
       "\n",
       "Cosine schedule function from `start` to `end`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedCos\n",
       "\n",
       ">      SchedCos (start, end)\n",
       "\n",
       "Cosine schedule function from `start` to `end`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SchedCos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedExp\n",
       "\n",
       ">      SchedExp (start, end)\n",
       "\n",
       "Exponential schedule function from `start` to `end`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedExp\n",
       "\n",
       ">      SchedExp (start, end)\n",
       "\n",
       "Exponential schedule function from `start` to `end`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SchedExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedLin\n",
       "\n",
       ">      SchedLin (start, end)\n",
       "\n",
       "Linear schedule function from `start` to `end`"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedLin\n",
       "\n",
       ">      SchedLin (start, end)\n",
       "\n",
       "Linear schedule function from `start` to `end`"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SchedLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedNo\n",
       "\n",
       ">      SchedNo (start, end)\n",
       "\n",
       "Constant schedule function with `start` value"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/fastai/fastai/blob/master/fastai/callback/schedule.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SchedNo\n",
       "\n",
       ">      SchedNo (start, end)\n",
       "\n",
       "Constant schedule function with `start` value"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SchedNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
