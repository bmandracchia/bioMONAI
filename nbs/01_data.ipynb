{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Data classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module introduces specialized classes to represent various bioimaging data structures, facilitating seamless integration with machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "from aicsimageio import AICSImage\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import stack as torch_stack\n",
    "\n",
    "from bioMONAI.datasets import download_medmnist\n",
    "from bioMONAI.core import MetaTensor, torchTensor, BypassNewMeta, DisplayedTransform, fastTrainer, torchsqueeze, Path, List, L, torchmax, randint, typedispatch, dictlist_to_funclist, read_yaml\n",
    "from bioMONAI.io import image_reader\n",
    "from bioMONAI.visualize import show_images_grid, show_multichannel\n",
    "\n",
    "from fastai.data.all import DataLoaders, delegates, RegexLabeller, is_listy, ColReader, ColSplitter\n",
    "from fastai.vision.all import DataBlock, CategoryBlock, MultiCategoryBlock, RegressionBlock, TfmdDL, get_image_files, TransformBlock, get_grid, merge, show_image, RandomSplitter, GrandparentSplitter, partial, parent_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MetaResolver(type(torchTensor), metaclass=BypassNewMeta):\n",
    "    \"\"\"\n",
    "    The `MetaResolver` class addresses metaclass conflicts, ensuring compatibility across different data structures. This is particularly useful when integrating with libraries that have specific metaclass requirements.\n",
    "    \"\"\"\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BioImageBase** is a function that acts as a base class for biomedical images. It can be used for many things, such as loading image data as PyTorch tensors, displaying 2D slices of 3D images and making transformations on medical images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BioImageBase(MetaTensor, metaclass=MetaResolver):\n",
    "    \"\"\"\n",
    "    Serving as the foundational class for bioimaging data, `BioImageBase` provides core functionalities for image handling. It ensures that instances of specified types are appropriately cast to this class, maintaining consistency in data representation.\n",
    "    \n",
    "    Metaclass casts `x` to this class if it is of type `cls._bypass_type`.\n",
    "    \"\"\"\n",
    "    \n",
    "    _bypass_type = torchTensor  # The type that bypasses image loading\n",
    "    _show_args = {'cmap': 'gray'}  # Default arguments for image display\n",
    "    resample, reorder = None, False  # Default resample and reorder settings\n",
    "    affine_matrix = None  # Default affine matrix for image transformation\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, fn: (Path, str, List, torchTensor), **kwargs) -> torchTensor: \n",
    "        \"\"\"\n",
    "        Opens an image and casts it to BioImageBase object.\n",
    "        If `fn` is a torchTensor, it's cast to BioImageBase object.\n",
    "\n",
    "        Args:\n",
    "            fn : (Path, str, torchTensor)\n",
    "                Image path or a 4D torchTensor.\n",
    "            kwargs : dict\n",
    "                Additional parameters for the medical image reader.\n",
    "\n",
    "        Returns:\n",
    "            torchTensor : A 4D tensor as a BioImageBase object.\n",
    "        \"\"\"\n",
    "        if isinstance(fn, torchTensor):\n",
    "            return cls(fn)\n",
    "\n",
    "        return image_reader(fn, dtype=cls, resample=cls.resample, reorder=cls.reorder)\n",
    "\n",
    "    @classmethod\n",
    "    def item_preprocessing(cls, resample: (List, int, tuple), reorder: bool):\n",
    "        \"\"\"\n",
    "        Changes the values for the class variables `resample` and `reorder`.\n",
    "\n",
    "        Args:\n",
    "            resample : (List, int, tuple)\n",
    "                A list with voxel spacing.\n",
    "            reorder : bool\n",
    "                Whether to reorder the data to be closest to canonical (RAS+) orientation.\n",
    "        \"\"\"\n",
    "        cls.resample = resample\n",
    "        cls.reorder = reorder\n",
    "\n",
    "    def show(self, ctx=None, figsize: int = None, ncols: int = 10, title=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Plots 2D slices of a 3D image alongside a prior specified axis.\n",
    "\n",
    "        Args:\n",
    "            ctx : Context to use for the display. Defaults to None.\n",
    "            figsize: Size of the figure. Defaults to None.\n",
    "            ncols: Number of columns in the grid. Defaults to 10.\n",
    "            **kwargs : Additional keyword arguments passed to plt.imshow.\n",
    "\n",
    "        Returns:\n",
    "            Shown image.\n",
    "        \"\"\"\n",
    "        return show_images_grid(self, ctx=ctx, ncols=ncols, title=[title], **merge(self._show_args, kwargs))\n",
    "    \n",
    "    def as_tensor(self) -> torchTensor:\n",
    "        \"\"\"\n",
    "        Return the `MetaTensor` as a `torchTensor`.\n",
    "        It is OS dependent as to whether this will be a deep copy or not.\n",
    "        \"\"\"\n",
    "        return self.as_subclass(torchTensor)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "        return f\"BioImageBase{self.as_tensor().__repr__()[6:]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BioImage** is a specialization of BioImageBase that is specifically used for 2D and 3D biomedical images. To do so, it directly inherits from that class and then squeezes the image data and allows for transformations to be made there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BioImage(BioImageBase):\n",
    "    \"\"\"\n",
    "    A subclass of `BioImageBase`, the `BioImage` class is tailored for handling both 2D and 3D image objects. It offers methods to load images from various formats and provides access to image properties such as shape and dimensions.\n",
    "    \"\"\"\n",
    "    _show_args = {'cmap':'gray'}\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, fn: (Path, str, L, list, torchTensor), **kwargs) -> torchTensor: \n",
    "        \"\"\"\n",
    "        Opens an image and casts it to BioImageBase object.\n",
    "        If `fn` is a torchTensor, it's cast to BioImageBase object.\n",
    "\n",
    "        Args:\n",
    "            fn : (Path, str, torchTensor)\n",
    "                Image path or a 4D torchTensor.\n",
    "            kwargs : dict\n",
    "                Additional parameters for the medical image reader.\n",
    "\n",
    "        Returns:\n",
    "            torchTensor : A 2D or 3D tensor as a BioImage object.\n",
    "        \"\"\"\n",
    "        if isinstance(fn, torchTensor):\n",
    "            return cls(fn)\n",
    "\n",
    "        return torchsqueeze(image_reader(fn, dtype=cls, resample=cls.resample, reorder=cls.reorder), 1)\n",
    "    \n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        \"Show image using `merge(self._show_args, kwargs)`\"\n",
    "        return show_image(self, ctx=ctx, **merge(self._show_args, kwargs))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "    #     return f'{self.__class__.__name__} shape={\"x\".join([str(d) for d in self.shape])}'\n",
    "        return f\"BioImage{self.as_tensor().__repr__()[6:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "a = BioImage.create('./data_examples/example_tiff.tiff')\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BioImageStack(BioImageBase):\n",
    "    \"\"\"\n",
    "    Designed for 3D image data, `BioImageStack` extends `BioImageBase` to manage volumetric images effectively. \n",
    "    It includes functionalities for slicing, visualization, and manipulation of 3D data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "        return f\"BioImageStack{self.as_tensor().__repr__()[6:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "a = BioImageStack.create('./data_examples/example_tiff.tiff')\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BioImageProject(BioImageBase):\n",
    "    \"\"\"\n",
    "    The `BioImageProject` class represents a 3D image stack as a 2D image using maximum intensity projection. This is particularly useful for visualizing volumetric data in a 2D format, aiding in quick assessments and presentations.\n",
    "    \"\"\"\n",
    "    _show_args = {'cmap':'gray'}\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, fn: (Path, str, L, list, torchTensor), **kwargs) -> torchTensor: \n",
    "        \"\"\"\n",
    "        Opens an image and casts it to BioImageBase object.\n",
    "        If `fn` is a torchTensor, it's cast to BioImageBase object.\n",
    "\n",
    "        Args:\n",
    "            fn : (Path, str, torchTensor)\n",
    "                Image path or a 4D torchTensor.\n",
    "            kwargs : dict\n",
    "                Additional parameters for the medical image reader.\n",
    "\n",
    "        Returns:\n",
    "            torchTensor : A 3D tensor as a BioImage object.\n",
    "        \"\"\"\n",
    "        if isinstance(fn, torchTensor):\n",
    "            return cls(fn)\n",
    "\n",
    "        img = image_reader(fn, dtype=cls, resample=cls.resample, reorder=cls.reorder)\n",
    "        return torchmax(img, dim=1)[0]  # Taking the maximum intensity projection along axis 1\n",
    "    \n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        \"Show image using `merge(self._show_args, kwargs)`\"\n",
    "        return show_image(self, ctx=ctx, **merge(self._show_args, kwargs))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "        return f\"BioImageProject{self.as_tensor().__repr__()[6:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = BioImageProject.create('./data_examples/example_tiff.tiff')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BioImageMulti(BioImageBase):\n",
    "    \"\"\"\n",
    "    For multi-channel 2D images, `BioImageMulti` extends `BioImageBase` to handle data with multiple channels, such as different fluorescence markers in microscopy images. \n",
    "    \"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, fn: (Path, str, L, list, torchTensor), **kwargs) -> torchTensor: \n",
    "        \"\"\"\n",
    "        Opens an image and casts it to BioImageBase object.\n",
    "        If `fn` is a torchTensor, it's cast to BioImageBase object.\n",
    "\n",
    "        Args:\n",
    "            fn : (Path, str, torchTensor)\n",
    "                Image path or a 4D torchTensor.\n",
    "            kwargs : dict\n",
    "                Additional parameters for the medical image reader.\n",
    "\n",
    "        Returns:\n",
    "            torchTensor : A 3D tensor as a BioImage object.\n",
    "        \"\"\"\n",
    "        if isinstance(fn, torchTensor):\n",
    "            return cls(fn)\n",
    "\n",
    "        return torchsqueeze(image_reader(fn, dtype=cls, resample=cls.resample, reorder=cls.reorder))\n",
    "    \n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        \"Show image using `merge(self._show_args, kwargs)`\"\n",
    "        return show_multichannel(self, ctx=ctx, **merge(self._show_args, kwargs))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "        return f\"BioImageMulti{self.as_tensor().__repr__()[6:]}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Load a 3D image stack as a multichannel image\n",
    "a = BioImageMulti.create('./data_examples/example_tiff.tiff')\n",
    "# Differently from BioImageStack, here the third dimension is encoded as channels.\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# show function should be implemented\n",
    "class BioImage4D(BioImageBase):\n",
    "    \"\"\"Subclass of BioImageBase that represents a (multi-channel) 3D image object.\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, fn: (Path, str, L, list, torchTensor), **kwargs) -> torchTensor: \n",
    "        \"\"\"\n",
    "        Opens an image and casts it to BioImageBase object.\n",
    "        If `fn` is a torchTensor, it's cast to BioImageBase object.\n",
    "\n",
    "        Args:\n",
    "            fn : (Path, str, torchTensor)\n",
    "                Image path or a 4D torchTensor.\n",
    "            kwargs : dict\n",
    "                Additional parameters for the medical image reader.\n",
    "\n",
    "        Returns:\n",
    "            torchTensor : A 3D tensor as a BioImage object.\n",
    "        \"\"\"\n",
    "        if isinstance(fn, torchTensor):\n",
    "            return cls(fn)\n",
    "\n",
    "        return torchsqueeze(image_reader(fn, dtype=cls, resample=cls.resample, reorder=cls.reorder), 1)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns the string representation of the ImageBase instance.\"\"\"\n",
    "        return f\"BioImage4D{self.as_tensor().__repr__()[6:]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate seamless integration between tensors and bioimaging data structures, the module provides conversion utilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Tensor2BioImage(DisplayedTransform):\n",
    "    \"\"\"\n",
    "    The `Tensor2BioImage` transform converts tensors into `BioImageBase` instances, enabling the application of bioimaging-specific methods to tensor data. \n",
    "    This is essential for integrating deep learning models with bioimaging workflows.\n",
    "    \"\"\"\n",
    "    def __init__(self, cls:BioImageBase=BioImageStack):\n",
    "        self.cls = cls\n",
    "\n",
    "    def encodes(self, o):\n",
    "        if isinstance(o, MetaTensor):\n",
    "            # return self.cls(o.clone(), affine=o.affine, meta=o.meta)\n",
    "            return self.cls(o.clone(), meta=o.meta)\n",
    "        \n",
    "        if isinstance(o, torchTensor):\n",
    "            return self.cls(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Blocks and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module offers classes to construct data blocks and data loaders, streamlining the preparation of datasets for machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BioImageBlock** Creates a new type of TransformBlock specifically for bioimaging data aside from other types like ImageBlock, CategoryBlock and TextBlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def BioImageBlock(cls:BioImageBase=BioImage):\n",
    "    \"A `TransformBlock` tailored for bioimaging data, `BioImageBlock` facilitates the creation of data processing pipelines, including transformations and augmentations specific to bioimaging.\"\n",
    "    return TransformBlock(type_tfms=[cls.create, Tensor2BioImage(cls)]) # IntToFloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **BioDataBlock** class is built on top of the DataBlock’s class which is provided by the fastai library and is used to build datasets and dataloaders from blocks specifically for biomedical data, offering additionally the option to use BioImageBlock as TransformBlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BioDataBlock(DataBlock):\n",
    "    \"\"\" \n",
    "    The `BioDataBlock` class serves as a generic container to build `Datasets` and `DataLoaders` efficiently. It integrates item and batch transformations, getters, and splitters, simplifying the setup of data pipelines for training and validation.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "            blocks:list=(BioImageBlock(cls=BioImage), BioImageBlock(cls=BioImage)), # One or more `TransformBlock`s\n",
    "            dl_type:TfmdDL=None,                                                    # Task specific `TfmdDL`, defaults to `block`'s dl_type or`TfmdDL`\n",
    "            get_items=get_image_files,\n",
    "            get_y=None,\n",
    "            get_x=None,\n",
    "            getters:list=None,                                                      # Getter functions applied to results of `get_items`\n",
    "            n_inp:int=None,                                                         # Number of inputs\n",
    "            item_tfms:list=None,                                                    # `ItemTransform`s, applied on an item \n",
    "            batch_tfms:list=None,                                                   # `Transform`s or `RandTransform`s, applied by batch\n",
    "            **kwargs, \n",
    "        ):\n",
    "        super().__init__(\n",
    "            blocks=blocks, \n",
    "            dl_type=dl_type, \n",
    "            get_items=get_items,\n",
    "            get_y=get_y,\n",
    "            get_x=get_x,\n",
    "            getters=getters, \n",
    "            n_inp=n_inp, \n",
    "            item_tfms=item_tfms, \n",
    "            batch_tfms=batch_tfms,\n",
    "            **kwargs,\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **BioDataLoaders** class is built on top of fastai’s DataLoaders class, and wraps various data loading methods as well as the use of BioImageBlock as TransformBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BioDataLoaders(DataLoaders):\n",
    "    \"\"\"\n",
    "    Basic wrapper around several `DataLoader`s with factory methods for biomedical imaging problems.\n",
    "    Managing multiple `DataLoader` instances, `BioDataLoaders` handles data loading for different phases of model training, such as training, validation, and testing. It ensures efficient data handling and supports various batch processing strategies.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    def from_source(cls, \n",
    "                    data_source, # The source of the data to be loaded by the dataloader. This can be any type that is compatible with the dataloading method specified in kwargs (e.g., paths, datasets).\n",
    "                    show_summary:bool=False, # If True, print a summary of the BioDataBlock after creation.\n",
    "                    **kwargs, # Additional keyword arguments to configure the DataLoader and BioDataBlock. Supported keys include: 'blocks', 'dl_type', 'get_items', 'get_y', 'get_x', 'getters', 'n_inp', 'item_tfms', 'batch_tfms'.\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Create and return a DataLoader from a BioDataBlock using provided keyword arguments.\n",
    "        \n",
    "        Returns a  DataLoader: A PyTorch DataLoader object populated with the data from the BioDataBlock.\n",
    "                        If show_summary is True, it also prints a summary of the datablock after creation.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Define the keys for BioDataBlock operations\n",
    "        datablock_ops_keys = ['blocks','dl_type','get_items','get_y','get_x','getters','n_inp','item_tfms','batch_tfms','splitter']\n",
    "        \n",
    "        # Filter and assign kwargs to datablock_ops dictionary for BioDataBlock initialization\n",
    "        datablock_ops = {key: value for key, value in kwargs.items() if key in datablock_ops_keys}\n",
    "        \n",
    "        # Filter and assign remaining kwargs to dataloader_ops dictionary for DataLoader creation\n",
    "        dataloader_ops = {key: value for key, value in kwargs.items() if key not in datablock_ops_keys}\n",
    "        \n",
    "        # Initialize BioDataBlock with specified operations\n",
    "        datablock = BioDataBlock(**datablock_ops)\n",
    "    \n",
    "        # Create and return the DataLoader from the initialized BioDataBlock\n",
    "        dataloder = datablock.dataloaders(data_source, **dataloader_ops)\n",
    "        \n",
    "        # Optionally print a summary of the BioDataBlock if show_summary is True\n",
    "        if show_summary:\n",
    "            bs = dataloader_ops['bs'] if dataloader_ops['bs'] is not None else 1\n",
    "            print(datablock.summary(data_source, bs=bs))\n",
    "        \n",
    "        return dataloder\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def from_folder(cls, path, get_target_fn, train='train', valid='valid', valid_pct=None, seed=None, item_tfms=None,\n",
    "                    batch_tfms=None, img_cls=BioImage, target_img_cls=BioImage, **kwargs):\n",
    "        \"Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)\"\n",
    "        splitter = GrandparentSplitter(train_name=train, valid_name=valid) if valid_pct is None else RandomSplitter(valid_pct, seed=seed)\n",
    "        get_items = get_image_files if valid_pct else partial(get_image_files, folders=[train, valid])\n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), BioImageBlock(target_img_cls)),\n",
    "            'get_items':    get_items,\n",
    "            'splitter':     splitter,\n",
    "            'get_y':        get_target_fn,\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source(path, **ops, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def from_df(cls, df, path='.', valid_pct=0.2, seed=None, fn_col=0, folder=None, pref=None, suff='', target_col=1, target_folder=None, target_suff='',\n",
    "                valid_col=None, item_tfms=None, batch_tfms=None, img_cls=BioImage, target_img_cls=BioImage, **kwargs):\n",
    "        \"Create from `df` using `fn_col` and `target_col`\"\n",
    "        if pref is None:\n",
    "            pref = f'{Path(path) if folder is None else Path(path)/folder}{os.path.sep}'\n",
    "        if folder is None:\n",
    "            target_pref = pref\n",
    "        else:\n",
    "            f'{Path(path)/target_folder}{os.path.sep}'\n",
    "        splitter = RandomSplitter(valid_pct, seed=seed) if valid_col is None else ColSplitter(valid_col)        \n",
    "        target_img_cls = img_cls if target_img_cls is None else target_img_cls\n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), BioImageBlock(target_img_cls)),\n",
    "            'get_items':    None,\n",
    "            'splitter':     splitter,\n",
    "            'get_x':        ColReader(fn_col, pref=pref, suff=suff),\n",
    "            'get_y':        ColReader(target_col, pref=target_pref, suff=target_suff),\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source(df, **ops, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    @delegates(from_df)\n",
    "    def from_csv(cls, path, csv_fname='train.csv', header='path', delimiter=None, quoting=0, **kwargs):\n",
    "        \"Create from `path/csv_fname` using `fn_col` and `target_col`\"\n",
    "        df = pd.read_csv(Path(path)/csv_fname, header=header, delimiter=delimiter, quoting=quoting)\n",
    "        return cls.from_df(df, path=path, **kwargs)\n",
    "       \n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def class_from_folder(cls, path, train='train', valid='valid', valid_pct=None, seed=None, vocab=None, item_tfms=None,\n",
    "                    batch_tfms=None, img_cls=BioImage, **kwargs):\n",
    "        \"Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)\"\n",
    "        splitter = GrandparentSplitter(train_name=train, valid_name=valid) if valid_pct is None else RandomSplitter(valid_pct, seed=seed)\n",
    "        get_items = get_image_files if valid_pct else partial(get_image_files, folders=[train, valid])\n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), CategoryBlock(vocab=vocab)),\n",
    "            'get_items':    get_items,\n",
    "            'splitter':     splitter,\n",
    "            'get_y':        parent_label,\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source(path, **ops, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def class_from_path_func(cls, path, fnames, label_func, valid_pct=0.2, seed=None, item_tfms=None, batch_tfms=None, \n",
    "                       img_cls=BioImage, **kwargs):\n",
    "        \"Create from list of `fnames` in `path`s with `label_func`\"\n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), CategoryBlock),\n",
    "            'splitter':     RandomSplitter(valid_pct, seed=seed),\n",
    "            'get_y':        label_func,\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source(fnames, **ops, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def class_from_path_re(cls, path, fnames, pat, **kwargs):\n",
    "        \"Create from list of `fnames` in `path`s with re expression `pat`\"\n",
    "        return cls.class_from_path_func(path, fnames, RegexLabeller(pat), **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def class_from_df(cls, df, path='.', valid_pct=0.2, seed=None, fn_col=0, folder=None, suff='', label_col=1, label_delim=None,\n",
    "                y_block=None, valid_col=None, item_tfms=None, batch_tfms=None, img_cls=BioImage, **kwargs):\n",
    "        \"Create from `df` using `fn_col` and `label_col`\"\n",
    "        pref = f'{Path(path) if folder is None else Path(path)/folder}{os.path.sep}'\n",
    "        if y_block is None:\n",
    "            is_multi = (is_listy(label_col) and len(label_col) > 1) or label_delim is not None\n",
    "            y_block = MultiCategoryBlock if is_multi else CategoryBlock\n",
    "        splitter = RandomSplitter(valid_pct, seed=seed) if valid_col is None else ColSplitter(valid_col)        \n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), y_block),\n",
    "            'get_items':    None,\n",
    "            'splitter':     splitter,\n",
    "            'get_x':        ColReader(fn_col, pref=pref, suff=suff),\n",
    "            'get_y':        ColReader(label_col, label_delim=label_delim),\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source(df, **ops, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    @delegates(class_from_df)\n",
    "    def class_from_csv(cls, path, csv_fname='labels.csv', header='infer', delimiter=None, quoting=0, **kwargs):\n",
    "        \"Create from `path/csv_fname` using `fn_col` and `label_col`\"\n",
    "        df = pd.read_csv(Path(path)/csv_fname, header=header, delimiter=delimiter, quoting=quoting)\n",
    "        return cls.class_from_df(df, path=path, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(from_source)\n",
    "    def class_from_lists(cls, path, fnames, labels, valid_pct=0.2, seed:int=None, y_block=None, item_tfms=None, batch_tfms=None,\n",
    "                   img_cls=BioImage, **kwargs):\n",
    "        \"Create from list of `fnames` and `labels` in `path`\"\n",
    "        if y_block is None:\n",
    "            y_block = MultiCategoryBlock if is_listy(labels[0]) and len(labels[0]) > 1 else (\n",
    "                RegressionBlock if isinstance(labels[0], float) else CategoryBlock)\n",
    "        ops = { \n",
    "            'blocks':       (BioImageBlock(img_cls), y_block),\n",
    "            'splitter':     RandomSplitter(valid_pct, seed=seed),\n",
    "            'item_tfms':    item_tfms,\n",
    "            'batch_tfms':   batch_tfms,\n",
    "            'path':         path,\n",
    "            }\n",
    "        return cls.from_source((fnames, labels), **ops, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_yaml(cls, data_source, yaml_path, show_summary:bool=False):\n",
    "\n",
    "        \"Create from `yaml_path` where `yaml_path` is a yaml file\"\n",
    "\n",
    "\n",
    "        # Read the yaml file to obtain a dictionary with the configuration\n",
    "        config = read_yaml(yaml_path)\n",
    "        \n",
    "        # Turn string Nones into Nonetype and remove keys where the value is set to Nonetype\n",
    "        config = {key: (None if value == \"None\" else value) for key, value in config.items()}\n",
    "\n",
    "        # DEFINE THE KEYS THAT ARE AVAILABLE FOR USE \n",
    "        # Define the keys used by fastTrainer\n",
    "        fastrainer_ops_keys = ['loss_fn', 'optimizer', 'lr', 'splitter', 'callbacks', 'metrics', 'path', 'model_dir', 'wd', \n",
    "                               'wd_bn_bias', 'train_bn', 'moms', 'default_cbs']\n",
    "        \n",
    "        # Define the keys used by biodataloader\n",
    "        biodataloader_ops_keys = ['bs', 'shuffle_train', 'shuffle', 'val_shuffle', 'n', 'path', 'dl_type', 'dl_kwargs', 'device', \n",
    "                                  'drop_last', 'val_bs', 'num_workers', 'verbose', 'do_setup', 'pin_memory', 'timeout', 'batch_size', \n",
    "                                  'indexed', 'persistent_workers', 'pin_memory_device', 'wif', 'before_iter', 'after_item', 'before_batch', \n",
    "                                  'after_batch', 'after_iter', 'create_batches', 'create_item', 'create_batch', 'retain', 'get_idxs', 'sample', \n",
    "                                  'shuffle_fn', 'do_batch']\n",
    "\n",
    "        # Define the keys used by biodatablocks\n",
    "        biodatablocks_ops_keys = ['blocks','dl_type','get_items','get_y','get_x','getters','n_inp','item_tfms','batch_tfms','splitter']\n",
    "\n",
    "\n",
    "        # FILTER THE YAML FILE TO ONLY INCLUDE THE KEYS THE VALID KEYS\n",
    "        biodatablock_ops = {key: value for key, value in config.items() if key in biodatablocks_ops_keys}\n",
    "        biodataloader_ops = {key: value for key, value in config.items() if key in biodataloader_ops_keys}\n",
    "\n",
    "\n",
    "        # Obtain and define default values for the splitter within the BioDataBlock\n",
    "        train = config.get('train', 'train') \n",
    "        valid = config.get('valid', 'val')  \n",
    "        valid_pct = config.get('valid_pct', None) \n",
    "        seed = config.get('seed', None) \n",
    "        \n",
    "\n",
    "        # Initialize the splitter\n",
    "        if valid_pct is not None:\n",
    "            splitter = RandomSplitter(valid_pct, seed=seed)\n",
    "            get_items = get_image_files  \n",
    "        else:\n",
    "            splitter = GrandparentSplitter(train_name=train, valid_name=valid)\n",
    "            get_items = partial(get_image_files, folders=[train, valid])  \n",
    "\n",
    "        # Turn item_tfms and batch_tfms into lists of functions \n",
    "        item_tfms = config.get('item_tfms', None)\n",
    "        if item_tfms is not None:\n",
    "            item_tfms = dictlist_to_funclist(item_tfms)\n",
    "\n",
    "        batch_tfms = config.get('batch_tfms', None)\n",
    "        if batch_tfms is not None:   \n",
    "            batch_tfms = dictlist_to_funclist(batch_tfms)\n",
    "\n",
    "        # Update biodatablock_ops with the splitter\n",
    "        biodatablock_ops.update({\n",
    "            \"blocks\": (BioImageBlock(cls=BioImage), CategoryBlock),\n",
    "            \"get_items\": get_items,\n",
    "            \"splitter\": splitter,\n",
    "            \"get_y\": parent_label,\n",
    "            \"item_tfms\": item_tfms,\n",
    "            \"batch_tfms\": batch_tfms\n",
    "        })\n",
    "\n",
    "         # Optionally print a summary of the BioDataBlock if show_summary is True\n",
    "        if show_summary:\n",
    "            bs = biodataloader_ops['bs'] if biodataloader_ops['bs'] is not None else 1\n",
    "            print(datablock.summary(data_source, bs=bs))\n",
    "        \n",
    "        \n",
    "        biodatablock_ops = {key: value for key, value in biodatablock_ops.items() if value is not None}\n",
    "\n",
    "        biodataloader_ops = {key: value for key, value in biodataloader_ops.items() if value is not None}\n",
    "        \n",
    "        # Create BioDataBlock\n",
    "        datablock = BioDataBlock(**biodatablock_ops)\n",
    "\n",
    "        # Unpack biodataloader_ops directly (including bs)\n",
    "        dataloder = datablock.dataloaders(data_source, **biodataloader_ops)\n",
    "\n",
    "\n",
    "       \n",
    "        return dataloder\n",
    "\n",
    "BioDataLoaders.class_from_csv = delegates(to=BioDataLoaders.class_from_df)(BioDataLoaders.class_from_csv)\n",
    "BioDataLoaders.class_from_path_re = delegates(to=BioDataLoaders.class_from_path_func)(BioDataLoaders.class_from_path_re)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_source\n",
       "\n",
       ">      BioDataLoaders.from_source (data_source, show_summary:bool=False,\n",
       ">                                  path:str|Path='.', bs:int=64,\n",
       ">                                  val_bs:int=None, shuffle:bool=True,\n",
       ">                                  device=None)\n",
       "\n",
       "*Create and return a DataLoader from a BioDataBlock using provided keyword arguments.\n",
       "\n",
       "Returns a  DataLoader: A PyTorch DataLoader object populated with the data from the BioDataBlock.\n",
       "                If show_summary is True, it also prints a summary of the datablock after creation.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data_source |  |  | The source of the data to be loaded by the dataloader. This can be any type that is compatible with the dataloading method specified in kwargs (e.g., paths, datasets). |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_source\n",
       "\n",
       ">      BioDataLoaders.from_source (data_source, show_summary:bool=False,\n",
       ">                                  path:str|Path='.', bs:int=64,\n",
       ">                                  val_bs:int=None, shuffle:bool=True,\n",
       ">                                  device=None)\n",
       "\n",
       "*Create and return a DataLoader from a BioDataBlock using provided keyword arguments.\n",
       "\n",
       "Returns a  DataLoader: A PyTorch DataLoader object populated with the data from the BioDataBlock.\n",
       "                If show_summary is True, it also prints a summary of the datablock after creation.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data_source |  |  | The source of the data to be loaded by the dataloader. This can be any type that is compatible with the dataloading method specified in kwargs (e.g., paths, datasets). |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.from_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_folder\n",
       "\n",
       ">      BioDataLoaders.from_folder (path, get_target_fn, train='train',\n",
       ">                                  valid='valid', valid_pct=None, seed=None,\n",
       ">                                  item_tfms=None, batch_tfms=None,\n",
       ">                                  img_cls=<class '__main__.BioImage'>,\n",
       ">                                  target_img_cls=<class '__main__.BioImage'>,\n",
       ">                                  show_summary:bool=False, bs:int=64,\n",
       ">                                  val_bs:int=None, shuffle:bool=True,\n",
       ">                                  device=None)\n",
       "\n",
       "*Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| get_target_fn |  |  |  |\n",
       "| train | str | train |  |\n",
       "| valid | str | valid |  |\n",
       "| valid_pct | NoneType | None |  |\n",
       "| seed | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_folder\n",
       "\n",
       ">      BioDataLoaders.from_folder (path, get_target_fn, train='train',\n",
       ">                                  valid='valid', valid_pct=None, seed=None,\n",
       ">                                  item_tfms=None, batch_tfms=None,\n",
       ">                                  img_cls=<class '__main__.BioImage'>,\n",
       ">                                  target_img_cls=<class '__main__.BioImage'>,\n",
       ">                                  show_summary:bool=False, bs:int=64,\n",
       ">                                  val_bs:int=None, shuffle:bool=True,\n",
       ">                                  device=None)\n",
       "\n",
       "*Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| get_target_fn |  |  |  |\n",
       "| train | str | train |  |\n",
       "| valid | str | valid |  |\n",
       "| valid_pct | NoneType | None |  |\n",
       "| seed | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_df\n",
       "\n",
       ">      BioDataLoaders.from_df (df, path='.', valid_pct=0.2, seed=None, fn_col=0,\n",
       ">                              folder=None, pref=None, suff='', target_col=1,\n",
       ">                              target_folder=None, target_suff='',\n",
       ">                              valid_col=None, item_tfms=None, batch_tfms=None,\n",
       ">                              img_cls=<class '__main__.BioImage'>,\n",
       ">                              target_img_cls=<class '__main__.BioImage'>,\n",
       ">                              show_summary:bool=False, bs:int=64,\n",
       ">                              val_bs:int=None, shuffle:bool=True, device=None)\n",
       "\n",
       "*Create from `df` using `fn_col` and `target_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| pref | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| target_col | int | 1 |  |\n",
       "| target_folder | NoneType | None |  |\n",
       "| target_suff | str |  |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_df\n",
       "\n",
       ">      BioDataLoaders.from_df (df, path='.', valid_pct=0.2, seed=None, fn_col=0,\n",
       ">                              folder=None, pref=None, suff='', target_col=1,\n",
       ">                              target_folder=None, target_suff='',\n",
       ">                              valid_col=None, item_tfms=None, batch_tfms=None,\n",
       ">                              img_cls=<class '__main__.BioImage'>,\n",
       ">                              target_img_cls=<class '__main__.BioImage'>,\n",
       ">                              show_summary:bool=False, bs:int=64,\n",
       ">                              val_bs:int=None, shuffle:bool=True, device=None)\n",
       "\n",
       "*Create from `df` using `fn_col` and `target_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| pref | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| target_col | int | 1 |  |\n",
       "| target_folder | NoneType | None |  |\n",
       "| target_suff | str |  |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.from_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L370){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_csv\n",
       "\n",
       ">      BioDataLoaders.from_csv (path, csv_fname='train.csv', header='path',\n",
       ">                               delimiter=None, quoting=0, valid_pct=0.2,\n",
       ">                               seed=None, fn_col=0, folder=None, pref=None,\n",
       ">                               suff='', target_col=1, target_folder=None,\n",
       ">                               target_suff='', valid_col=None, item_tfms=None,\n",
       ">                               batch_tfms=None, img_cls=<class\n",
       ">                               '__main__.BioImage'>, target_img_cls=<class\n",
       ">                               '__main__.BioImage'>, show_summary:bool=False,\n",
       ">                               bs:int=64, val_bs:int=None, shuffle:bool=True,\n",
       ">                               device=None)\n",
       "\n",
       "*Create from `path/csv_fname` using `fn_col` and `target_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| csv_fname | str | train.csv |  |\n",
       "| header | str | path |  |\n",
       "| delimiter | NoneType | None |  |\n",
       "| quoting | int | 0 |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| pref | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| target_col | int | 1 |  |\n",
       "| target_folder | NoneType | None |  |\n",
       "| target_suff | str |  |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L370){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.from_csv\n",
       "\n",
       ">      BioDataLoaders.from_csv (path, csv_fname='train.csv', header='path',\n",
       ">                               delimiter=None, quoting=0, valid_pct=0.2,\n",
       ">                               seed=None, fn_col=0, folder=None, pref=None,\n",
       ">                               suff='', target_col=1, target_folder=None,\n",
       ">                               target_suff='', valid_col=None, item_tfms=None,\n",
       ">                               batch_tfms=None, img_cls=<class\n",
       ">                               '__main__.BioImage'>, target_img_cls=<class\n",
       ">                               '__main__.BioImage'>, show_summary:bool=False,\n",
       ">                               bs:int=64, val_bs:int=None, shuffle:bool=True,\n",
       ">                               device=None)\n",
       "\n",
       "*Create from `path/csv_fname` using `fn_col` and `target_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| csv_fname | str | train.csv |  |\n",
       "| header | str | path |  |\n",
       "| delimiter | NoneType | None |  |\n",
       "| quoting | int | 0 |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| pref | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| target_col | int | 1 |  |\n",
       "| target_folder | NoneType | None |  |\n",
       "| target_suff | str |  |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| target_img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L377){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_folder\n",
       "\n",
       ">      BioDataLoaders.class_from_folder (path, train='train', valid='valid',\n",
       ">                                        valid_pct=None, seed=None, vocab=None,\n",
       ">                                        item_tfms=None, batch_tfms=None,\n",
       ">                                        img_cls=<class '__main__.BioImage'>,\n",
       ">                                        show_summary:bool=False, bs:int=64,\n",
       ">                                        val_bs:int=None, shuffle:bool=True,\n",
       ">                                        device=None)\n",
       "\n",
       "*Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| train | str | train |  |\n",
       "| valid | str | valid |  |\n",
       "| valid_pct | NoneType | None |  |\n",
       "| seed | NoneType | None |  |\n",
       "| vocab | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L377){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_folder\n",
       "\n",
       ">      BioDataLoaders.class_from_folder (path, train='train', valid='valid',\n",
       ">                                        valid_pct=None, seed=None, vocab=None,\n",
       ">                                        item_tfms=None, batch_tfms=None,\n",
       ">                                        img_cls=<class '__main__.BioImage'>,\n",
       ">                                        show_summary:bool=False, bs:int=64,\n",
       ">                                        val_bs:int=None, shuffle:bool=True,\n",
       ">                                        device=None)\n",
       "\n",
       "*Create from dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| train | str | train |  |\n",
       "| valid | str | valid |  |\n",
       "| valid_pct | NoneType | None |  |\n",
       "| seed | NoneType | None |  |\n",
       "| vocab | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.class_from_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L415){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_df\n",
       "\n",
       ">      BioDataLoaders.class_from_df (df, path='.', valid_pct=0.2, seed=None,\n",
       ">                                    fn_col=0, folder=None, suff='',\n",
       ">                                    label_col=1, label_delim=None,\n",
       ">                                    y_block=None, valid_col=None,\n",
       ">                                    item_tfms=None, batch_tfms=None,\n",
       ">                                    img_cls=<class '__main__.BioImage'>,\n",
       ">                                    show_summary:bool=False, bs:int=64,\n",
       ">                                    val_bs:int=None, shuffle:bool=True,\n",
       ">                                    device=None)\n",
       "\n",
       "*Create from `df` using `fn_col` and `label_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| label_col | int | 1 |  |\n",
       "| label_delim | NoneType | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L415){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_df\n",
       "\n",
       ">      BioDataLoaders.class_from_df (df, path='.', valid_pct=0.2, seed=None,\n",
       ">                                    fn_col=0, folder=None, suff='',\n",
       ">                                    label_col=1, label_delim=None,\n",
       ">                                    y_block=None, valid_col=None,\n",
       ">                                    item_tfms=None, batch_tfms=None,\n",
       ">                                    img_cls=<class '__main__.BioImage'>,\n",
       ">                                    show_summary:bool=False, bs:int=64,\n",
       ">                                    val_bs:int=None, shuffle:bool=True,\n",
       ">                                    device=None)\n",
       "\n",
       "*Create from `df` using `fn_col` and `label_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df |  |  |  |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| label_col | int | 1 |  |\n",
       "| label_delim | NoneType | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.class_from_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L437){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_csv\n",
       "\n",
       ">      BioDataLoaders.class_from_csv (path, csv_fname='labels.csv',\n",
       ">                                     header='infer', delimiter=None, quoting=0,\n",
       ">                                     valid_pct=0.2, seed=None, fn_col=0,\n",
       ">                                     folder=None, suff='', label_col=1,\n",
       ">                                     label_delim=None, y_block=None,\n",
       ">                                     valid_col=None, item_tfms=None,\n",
       ">                                     batch_tfms=None, img_cls=<class\n",
       ">                                     '__main__.BioImage'>,\n",
       ">                                     show_summary:bool=False, bs:int=64,\n",
       ">                                     val_bs:int=None, shuffle:bool=True,\n",
       ">                                     device=None)\n",
       "\n",
       "*Create from `path/csv_fname` using `fn_col` and `label_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| csv_fname | str | labels.csv |  |\n",
       "| header | str | infer |  |\n",
       "| delimiter | NoneType | None |  |\n",
       "| quoting | int | 0 |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| label_col | int | 1 |  |\n",
       "| label_delim | NoneType | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L437){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_csv\n",
       "\n",
       ">      BioDataLoaders.class_from_csv (path, csv_fname='labels.csv',\n",
       ">                                     header='infer', delimiter=None, quoting=0,\n",
       ">                                     valid_pct=0.2, seed=None, fn_col=0,\n",
       ">                                     folder=None, suff='', label_col=1,\n",
       ">                                     label_delim=None, y_block=None,\n",
       ">                                     valid_col=None, item_tfms=None,\n",
       ">                                     batch_tfms=None, img_cls=<class\n",
       ">                                     '__main__.BioImage'>,\n",
       ">                                     show_summary:bool=False, bs:int=64,\n",
       ">                                     val_bs:int=None, shuffle:bool=True,\n",
       ">                                     device=None)\n",
       "\n",
       "*Create from `path/csv_fname` using `fn_col` and `label_col`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| csv_fname | str | labels.csv |  |\n",
       "| header | str | infer |  |\n",
       "| delimiter | NoneType | None |  |\n",
       "| quoting | int | 0 |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | NoneType | None |  |\n",
       "| fn_col | int | 0 |  |\n",
       "| folder | NoneType | None |  |\n",
       "| suff | str |  |  |\n",
       "| label_col | int | 1 |  |\n",
       "| label_delim | NoneType | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| valid_col | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.class_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L444){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_lists\n",
       "\n",
       ">      BioDataLoaders.class_from_lists (path, fnames, labels, valid_pct=0.2,\n",
       ">                                       seed:int=None, y_block=None,\n",
       ">                                       item_tfms=None, batch_tfms=None,\n",
       ">                                       img_cls=<class '__main__.BioImage'>,\n",
       ">                                       show_summary:bool=False, bs:int=64,\n",
       ">                                       val_bs:int=None, shuffle:bool=True,\n",
       ">                                       device=None)\n",
       "\n",
       "*Create from list of `fnames` and `labels` in `path`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| fnames |  |  |  |\n",
       "| labels |  |  |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | int | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/deepCLEM/bioMONAI/blob/main/bioMONAI/data.py#L444){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BioDataLoaders.class_from_lists\n",
       "\n",
       ">      BioDataLoaders.class_from_lists (path, fnames, labels, valid_pct=0.2,\n",
       ">                                       seed:int=None, y_block=None,\n",
       ">                                       item_tfms=None, batch_tfms=None,\n",
       ">                                       img_cls=<class '__main__.BioImage'>,\n",
       ">                                       show_summary:bool=False, bs:int=64,\n",
       ">                                       val_bs:int=None, shuffle:bool=True,\n",
       ">                                       device=None)\n",
       "\n",
       "*Create from list of `fnames` and `labels` in `path`*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path | . | Path to put in `DataLoaders` |\n",
       "| fnames |  |  |  |\n",
       "| labels |  |  |  |\n",
       "| valid_pct | float | 0.2 |  |\n",
       "| seed | int | None |  |\n",
       "| y_block | NoneType | None |  |\n",
       "| item_tfms | NoneType | None |  |\n",
       "| batch_tfms | NoneType | None |  |\n",
       "| img_cls | MetaResolver | BioImage |  |\n",
       "| show_summary | bool | False | If True, print a summary of the BioDataBlock after creation. |\n",
       "| bs | int | 64 | Size of batch |\n",
       "| val_bs | int | None | Size of batch for validation `DataLoader` |\n",
       "| shuffle | bool | True | Whether to shuffle data |\n",
       "| device | NoneType | None | Device to put `DataLoaders` |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BioDataLoaders.class_from_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: train a model with configuration from a YAML file loading the data from the YAML file too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "# from monai.networks.nets import SEResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = '../_data'\n",
    "# batch_size = 32\n",
    "# path = Path(image_path)/'bloodmnist'\n",
    "# path_train = path/'train'\n",
    "# path_val = path/'val'\n",
    "\n",
    "# # Path to the YAML configuration file\n",
    "# yaml_path = './data_examples/sample_config.yml'\n",
    "\n",
    "# # Create BioDataLoaders instance from YAML with optional overrides\n",
    "# dataloaders = BioDataLoaders.from_yaml(\n",
    "#     path,\n",
    "#     yaml_path,\n",
    "#     show_summary = False\n",
    "# )\n",
    "\n",
    "# model = SEResNet50(spatial_dims=2,\n",
    "#                    in_channels=3,   \n",
    "#                    num_classes=8)    \n",
    "\n",
    "\n",
    "# # Define the trainer and load the data from the yaml file \n",
    "# trainer = fastTrainer.from_yaml(dataloaders, model, yaml_path)\n",
    "\n",
    "# # Train the model\n",
    "# trainer.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data getters\n",
    "\n",
    "Functions to retrieve specific data components are provided, aiding in the organization and preprocessing of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.vision.all import get_image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_gt(path_gt, # The base directory where the ground truth files are stored, or a file path from which to derive the parent directory.\n",
    "           gt_file_name=\"avg50.png\", # The name of the ground truth file.\n",
    "           ):\n",
    "    \"\"\"\n",
    "    The `get_gt` function retrieves ground truth data, essential for supervised learning tasks. \n",
    "    It ensures that the correct labels or annotations are associated with each data sample.\n",
    "    \n",
    "    This function constructs a path to a ground truth file based on the given `path_gt` and `gt_file_name`.    \n",
    "    It uses a lambda function to create a new path by appending `gt_file_name` to \n",
    "    the parent directory of the input file, as specified by `path_gt`.\n",
    "    \n",
    "    Returns a callable: A function that takes a single argument (a filename) and returns a Path object \n",
    "                   representing the full path to the ground truth file. When called with a filename, \n",
    "                   this function constructs the path by combining `path_gt` or the parent directory of \n",
    "                   the filename with `gt_file_name`. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert path_gt to Path object if it's a string\n",
    "    path_gt = Path(path_gt)\n",
    "    \n",
    "    # Define the lambda function that constructs the full path\n",
    "    _fn = lambda fn: path_gt / f\"{Path(fn).parent}\" / gt_file_name\n",
    "    \n",
    "    return _fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `get_gt`, the `get_target` function fetches target data for training, validation, or testing, facilitating the preparation of datasets for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_target(path:str, # The base directory where the files are located. This should be a string representing an absolute or relative path.\n",
    "               same_filename=True, #If True, the target file name will match the original file name; otherwise, it will use the specified prefix. \n",
    "               target_file_prefix=\"target\", # The prefix to insert into the target file name if `same_filename` is False. \n",
    "               signal_file_prefix=\"signal\", # The prefix used in the original file names that should be replaced by the target prefix. \n",
    "               relative_path=False, # If True, it indicates that the path is relative to the parent folder in the path where the input files are located.\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Constructs and returns functions for generating file paths to \"target\" files based on given input parameters.\n",
    "    \n",
    "    This function defines two nested helper functions within its scope: \\n\n",
    "        - `construct_target_filename(file_name)`: Constructs a target file name by inserting the specified prefix into the original file name.\n",
    "        - `generate_target_path(file_name)`: Generates a path to the target file based on whether `same_filename` is set to True or False.\n",
    "    \n",
    "    The main function returns the appropriate helper function based on the value of `same_filename`.\n",
    "    \n",
    "    Returns a callable: A function that takes a file name as input and returns its corresponding target file path based on the specified parameters.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define a function to construct the target file name based on input parameters\n",
    "    def construct_target_filename(file_name):\n",
    "        # Split the file name based on the signal file prefix\n",
    "        parts = file_name.split(signal_file_prefix)\n",
    "        \n",
    "        # Construct the target file name by inserting the target file prefix\n",
    "        target_file_name = parts[0] + target_file_prefix + parts[1]\n",
    "        \n",
    "        return target_file_name\n",
    "    \n",
    "    # Define a function to generate the target file path based on the given file name\n",
    "    def generate_target_path(file_name):\n",
    "        \n",
    "        base_path = ''\n",
    "        \n",
    "        if relative_path:\n",
    "            base_path = Path(file_name).parents[1]\n",
    "                            \n",
    "        # Extract the base file name\n",
    "        base_filename = os.path.basename(file_name)\n",
    "        \n",
    "        # If same_filename is True, simply return the path joined with the base file name\n",
    "        if same_filename:\n",
    "            return base_path / Path(path) / base_filename\n",
    "        \n",
    "        # If same_filename is False, construct the target file name and return the path joined with it\n",
    "        target_filename = construct_target_filename(base_filename)\n",
    "        return base_path / Path(path) / target_filename\n",
    "    \n",
    "    # Return the appropriate function based on the value of same_filename\n",
    "    return generate_target_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folder/target/target01.tif\n",
      "../train_folder/target/image01.tif\n"
     ]
    }
   ],
   "source": [
    "print(get_target('train_folder/target', same_filename=False)('../signal/signal01.tif'))\n",
    "print(get_target('target', relative_path=True)('../train_folder/signal/image01.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folder/GT/image_clean.tif\n"
     ]
    }
   ],
   "source": [
    "print(get_target('GT', relative_path=True, same_filename=False, target_file_prefix=\"image_clean\", signal_file_prefix=\"image_noisy\")('train_folder/signal/image_noisy.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tasks involving denoising or noise analysis, `get_noisy_pair` retrieves pairs of clean and noisy data, enabling the training of models to learn noise reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_noisy_pair(fn):\n",
    "    \"\"\"\n",
    "    Get another \"noisy\" version of the input file by selecting a file from the same directory.\n",
    "    \n",
    "    This function first retrieves all image files in the directory of the input file `fn` (excluding subdirectories). \n",
    "    It then selects one of these files at random, ensuring that it is not the original file itself to avoid creating a trivial \"noisy\" pair.\n",
    "    \n",
    "    Parameters: \\n\n",
    "        fn (Path or str): The path to the original image file. This should be a Path object but accepts string inputs for convenience.\n",
    "    \n",
    "    Returns: \\n\n",
    "        Path: A Path object pointing to the selected noisy file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert fn to Path object if it's not already one\n",
    "    fn = Path(fn)\n",
    "    \n",
    "    # Get all image files in the parent directory of the input file\n",
    "    tmp = get_image_files(fn.parent, recurse=False)\n",
    "    \n",
    "    # Select a random file from the list, ensuring it's not the original file\n",
    "    fn2 = tmp[randint(0, len(tmp) - 1)]\n",
    "    while fn2 == fn:\n",
    "        fn2 = tmp[randint(0, len(tmp) - 1)]\n",
    "    \n",
    "    return fn2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization functions are included to display batches of data and model results, aiding in qualitative assessments and debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typedispatch\n",
    "def show_batch(x: BioImageBase,     # The input image data.\n",
    "               y: BioImageBase,     # The target image data.\n",
    "               samples,             # List of sample indices to display.\n",
    "               ctxs=None,           # List of contexts for displaying images. If None, create new ones using get_grid().\n",
    "               max_n: int=10,       # Maximum number of samples to display. Default is 10.\n",
    "               nrows: int=None,     # Number of rows in the grid if ctxs are not provided.\n",
    "               ncols: int=None,     # Number of columns in the grid if ctxs are not provided.\n",
    "               figsize: tuple=None, # Figure size for the image display.\n",
    "               **kwargs,            # Additional keyword arguments to pass to the show method of BioImageBase.\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Display a batch of images and their corresponding targets.\n",
    "    \n",
    "    Returns:\n",
    "        List[Context]: A list of contexts after displaying the images and targets.\n",
    "    \"\"\"\n",
    "    # If ctxs are not provided, create new ones using get_grid()\n",
    "    if ctxs is None:\n",
    "        ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize, double=True)\n",
    "    \n",
    "    # Loop through the images and targets in pairs (x and y)\n",
    "    for i in range(2):\n",
    "        # Display each image-target pair in a specific context\n",
    "        ctxs[i::2] = [b.show(ctx=c, **kwargs) for b, c, _ in zip(samples.itemgot(i), ctxs[i::2], range(max_n))]\n",
    "    \n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.vision.all import TensorCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typedispatch\n",
    "def show_batch(x: BioImageBase,      # The input image data.\n",
    "               y: TensorCategory,    # The target data (categorical labels).\n",
    "               samples,              # List of sample indices to display.\n",
    "               ctxs=None,            # List of contexts for displaying images. If None, create new ones using get_grid().\n",
    "               max_n: int=10,        # Maximum number of samples to display. Default is 10.\n",
    "               nrows: int=None,      # Number of rows in the grid if ctxs are not provided.\n",
    "               ncols: int=None,      # Number of columns in the grid if ctxs are not provided.\n",
    "               figsize: tuple=None,  # Figure size for the image display.\n",
    "               **kwargs,             # Additional keyword arguments to pass to the show method of BioImageBase.\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Display a batch of images with their corresponding labels as titles.\n",
    "    \n",
    "    Returns:\n",
    "        List[Context]: A list of contexts after displaying the images and their labels.\n",
    "    \"\"\"\n",
    "    # If ctxs are not provided, create new ones using get_grid()\n",
    "    if ctxs is None: \n",
    "        ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    \n",
    "    # Flatten the context in case it returns as an array\n",
    "    if isinstance(ctxs, np.ndarray):\n",
    "        ctxs = ctxs.flatten()\n",
    "    \n",
    "    # Extract the input images and the corresponding labels\n",
    "    xs, ys = samples.itemgot(0), samples.itemgot(1)\n",
    "\n",
    "    # Loop through the images and labels\n",
    "    for i in range(len(xs)):\n",
    "        # Display each input image\n",
    "        ctxs[i] = xs[i].show(ctx=ctxs[i], title=f\"Label: {ys[i]}\", **kwargs)\n",
    "    \n",
    "    return ctxs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_batch\n",
    "> ```  \n",
    "> show_batch (x:BioImageBase, y:BioImageBase, samples,\n",
    ">             ctxs=None, max_n:int=10, nrows:int=None, ncols:int=None,\n",
    ">             figsize:tuple=None, **kwargs)\n",
    "> ```\n",
    "\n",
    "\n",
    "The `show_batch` function visualizes a batch of data samples, allowing users to inspect the input data and verify preprocessing steps.\n",
    "\n",
    "Returns: List[Context]: A list of contexts after displaying the images and labels.\n",
    "\n",
    "| | Type           | Default     | Details                                                         |\n",
    "|-----------|-----|-------------|-----------------------------------------------------------------|\n",
    "| x              | BioImageBase | | The input image data.                                           |\n",
    "| y              | BioImageBase | | The target label data.                                          |\n",
    "| samples        |             | | List of sample indices to display.                              |\n",
    "| ctxs           | NoneType     | | List of contexts for displaying images. If None, create new ones using `get_grid()`. |\n",
    "| max_n          | int          | 10 | Maximum number of samples to display.        |\n",
    "| nrows          | int          | None | Number of rows in the grid if `ctxs` are not provided.      |\n",
    "| ncols          | int          | None | Number of columns in the grid if `ctxs` are not provided.   |\n",
    "| figsize        | tuple        | None | Figure size for the image display.                          |\n",
    "| kwargs         |            | | Additional keyword arguments.                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "@typedispatch\n",
    "def show_results(x: BioImageBase, # The input image data.\n",
    "                 y: BioImageBase, # The target label data.\n",
    "                 samples, # List of sample indices to display.\n",
    "                 outs, # List of output predictions corresponding to the samples.\n",
    "                 ctxs=None, # List of contexts for displaying images. If None, create new ones using get_grid().\n",
    "                 max_n=10, # Maximum number of samples to display.\n",
    "                 figsize=None, # Figure size for the image display.\n",
    "                 **kwargs, # Additional keyword arguments to pass to the show method of BioImageBase.\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Display a batch of input images along with their predicted and target labels.\n",
    "   \n",
    "    Returns: \\n\n",
    "        List[Context]: A list of contexts after displaying the images and labels.\n",
    "    \"\"\"\n",
    "    # If ctxs are not provided, create new ones using get_grid() with a specific title and size\n",
    "    if ctxs is None: \n",
    "        ctxs = get_grid(3 * min(len(samples), max_n), ncols=3, figsize=figsize, title='Input/Target/Prediction')\n",
    "    \n",
    "    # Loop through the images and display them in a specific context for input (x) and output predictions (outs)\n",
    "    for i in range(2):\n",
    "        ctxs[i::3] = [b.show(ctx=c, **kwargs) for b, c, _ in zip(samples.itemgot(i), ctxs[i::3], range(max_n))]\n",
    "    \n",
    "    # Display the target labels (y) in a specific context after the input images\n",
    "    ctxs[2::3] = [b.show(ctx=c, **kwargs) for b, c, _ in zip(outs.itemgot(0), ctxs[2::3], range(max_n))]\n",
    "    \n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typedispatch\n",
    "def show_results(x: BioImageBase,       # The input image data.\n",
    "                y: TensorCategory,      # The target data (categorical labels).\n",
    "                samples,                # List of sample indices to display.\n",
    "                outs,                   # List of output predictions corresponding to the samples.\n",
    "                ctxs=None,              # List of contexts for displaying images. If None, create new ones using get_grid().\n",
    "                max_n=10,               # Maximum number of samples to display.\n",
    "                nrows: int=None,        # Number of rows in the grid if ctxs are not provided.\n",
    "                ncols: int=None,        # Number of columns in the grid if ctxs are not provided.\n",
    "                figsize=None,           # Figure size for the image display.\n",
    "                **kwargs,               # Additional keyword arguments to pass to the show method of BioImageBase.\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Display a batch of input images along with their predicted and target labels.\n",
    "   \n",
    "    Returns: \\n\n",
    "        List[Context]: A list of contexts after displaying the images and labels.\n",
    "    \"\"\"\n",
    "    # If ctxs are not provided, create new ones using get_grid() with a specific title and size\n",
    "    if ctxs is None: \n",
    "        ctxs = get_grid(min(len(samples), max_n), nrows=nrows, ncols=ncols, figsize=figsize, title='Target/Prediction')\n",
    "    \n",
    "    # Loop through the images and display them in a specific context for input (x) and output predictions (outs)\n",
    "    for i in range(2):\n",
    "        ctxs = [b.show(ctx=c, **kwargs) for b,c,_ in zip(samples.itemgot(i),ctxs,range(max_n))]\n",
    "    \n",
    "    # Display predictions and target labels (y) in green, when matching, or red, otherwise.\n",
    "    ctxs = [r.show(ctx=c, color='green' if b==r else 'red', **kwargs)\n",
    "            for b,r,c,_ in zip(samples.itemgot(1), outs.itemgot(0), ctxs, range(max_n))]\n",
    "    \n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show_results\n",
    "> ```\n",
    "> show_results (x: BioImageBase, y: BioImageBase, samples,\n",
    ">               outs, ctxs=None, max_n=10, figsize=None, **kwargs)\n",
    "> ```\n",
    "\n",
    "After model inference, `show_results` displays the model's predictions alongside the ground truth, facilitating the evaluation of model performance.\n",
    "\n",
    "Returns:\n",
    "\n",
    "List[Context]: A list of contexts after displaying the images and labels.\n",
    "\n",
    "\n",
    "|   | Type           | Default     | Details                                                         |\n",
    "|-----------|-----|-------------|-----------------------------------------------------------------|\n",
    "| x              | BioImageBase | | The input image data.                                           |\n",
    "| y              | BioImageBase | | The target label data.                                          |\n",
    "| samples        |             | | List of sample indices to display.                              |\n",
    "| outs           |          |   | List of output predictions corresponding to the samples. |\n",
    "| ctxs           | NoneType     | | List of contexts for displaying images. If None, create new ones using `get_grid()`. |\n",
    "| max_n          | int        | 10  | \n",
    "| figsize        | tuple        | None | Figure size for the image display.                          |\n",
    "| kwargs         |            | | Additional keyword arguments.                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module provides functions for data preprocessing, including patch extraction and dimensionality reduction, essential for preparing data for machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_patches(data, # numpy array of the input data (n-dimensional).\n",
    "                    patch_size, # tuple of integers defining the size of the patches in each dimension.\n",
    "                    overlap, # float (between 0 and 1) indicating overlap between patches.\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Extracts n-dimensional patches from the input data.\n",
    "\n",
    "    Returns:\n",
    "    - A list of patches as numpy arrays.\n",
    "    \"\"\"\n",
    "    data_shape = data.shape\n",
    "    strides = tuple(int(p * (1 - overlap)) for p in patch_size)  # Calculate the stride for each dimension\n",
    "    \n",
    "    # Compute the range of indices for each dimension\n",
    "    slices = [range(0, data_shape[i] - patch_size[i] + 1, strides[i]) for i in range(len(patch_size))]\n",
    "    \n",
    "    # Generate patches\n",
    "    patches = []\n",
    "    for indices in np.ndindex(*[len(s) for s in slices]):\n",
    "        # Create slices for each dimension\n",
    "        patch_slices = tuple(slice(slices[dim][idx], slices[dim][idx] + patch_size[dim]) for dim, idx in enumerate(indices))\n",
    "        patches.append(data[patch_slices])\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `extract_patches` function divides images into smaller patches, which is useful for training models on localized regions of interest, especially when dealing with high-resolution images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated patches: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.random.rand(100, 100, 3)  # Example 3D data\n",
    "patch_size = (64,64,2)\n",
    "overlap = 0.5\n",
    "patches = extract_patches(data, patch_size, overlap)\n",
    "print(\"Number of generated patches:\", len(patches))\n",
    "patches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_patches_grid(data_folder, # Path to the folder containing data files (n-dimensional data).\n",
    "                      gt_folder, # Path to the folder containing ground truth (gt) files (n-dimensional data).\n",
    "                      output_folder, # Path to the folder where the HDF5 files will be saved.\n",
    "                      patch_size, # tuple of integers defining the size of the patches.\n",
    "                      overlap, # float (between 0 and 1) defining the overlap between patches.\n",
    "                      threshold=None, # If provided, patches with a mean value below this threshold will be discarded.\n",
    "                      squeeze_input=True, #\n",
    "                      squeeze_patches=False, #\n",
    "                      csv_output=True, # If True, a CSV file listing all patch paths is created.\n",
    "                      train_test_split_ratio=0.8, # Ratio of data to split into train and test CSV files (e.g., 0.8 for 80% train).\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Loads n-dimensional data from data_folder and gt_folder, generates patches, and saves them into individual HDF5 files.\n",
    "    Each HDF5 file will have datasets with the structure X/patch_idx and y/patch_idx.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Ensure the folders contain the same number of files\n",
    "    data_files = sorted([f for f in os.listdir(data_folder) if f.endswith(('.npy', '.npz', '.png', '.tif', '.tiff'))])\n",
    "    gt_files = sorted([f for f in os.listdir(gt_folder) if f.endswith(('.npy', '.npz', '.png', '.tif', '.tiff'))])\n",
    "\n",
    "    if len(data_files) != len(gt_files):\n",
    "        raise ValueError(\"The number of files in data_folder and gt_folder must be the same.\")\n",
    "    \n",
    "    # Prepare CSV records list\n",
    "    csv_records = []\n",
    "\n",
    "    # Loop through the files in the folders\n",
    "    for data_file_name, gt_file_name in tqdm(zip(data_files, gt_files), total=len(data_files), desc=\"Processing files\"):\n",
    "        data_file_path = os.path.join(data_folder, data_file_name)\n",
    "        gt_file_path = os.path.join(gt_folder, gt_file_name)\n",
    "        \n",
    "        # Load the images\n",
    "        data = np.array(image_reader(data_file_path))\n",
    "        gt = np.array(image_reader(gt_file_path))\n",
    "        \n",
    "        if squeeze_input:\n",
    "            data = np.squeeze(data)\n",
    "            gt = np.squeeze(gt)\n",
    "        \n",
    "        if data.shape != gt.shape:\n",
    "            raise ValueError(f\"Shape mismatch between {data_file_name} and {gt_file_name}\")\n",
    "        \n",
    "        # Extract patches from both datasets\n",
    "        data_patches_nd = extract_patches(data, patch_size, overlap)\n",
    "        gt_patches_nd = extract_patches(gt, patch_size, overlap)\n",
    "        \n",
    "        if squeeze_patches:\n",
    "            data_patches_nd = np.squeeze(data_patches_nd)\n",
    "            gt_patches_nd = np.squeeze(gt_patches_nd)\n",
    "        \n",
    "        # Create a new HDF5 file for this pair of files\n",
    "        hdf5_filename = os.path.join(output_folder, f\"{os.path.splitext(data_file_name)[0]}.h5\")\n",
    "        \n",
    "        with h5py.File(hdf5_filename, 'w') as hf:\n",
    "            patch_counter = 0  # Counter to number the valid patches\n",
    "            \n",
    "            # Store each patch in a separate dataset\n",
    "            for data_patch, gt_patch in tqdm(zip(data_patches_nd, gt_patches_nd), \n",
    "                                             total=len(data_patches_nd), \n",
    "                                             desc=f\"Saving patches for {data_file_name}\", \n",
    "                                             leave=False):\n",
    "                # Calculate the mean of the patch and discard if below threshold (if provided)\n",
    "                if threshold is not None and np.mean(data_patch) < threshold:\n",
    "                    continue  # Skip this patch\n",
    "                \n",
    "                hf.create_dataset(f'X/{patch_counter}', data=data_patch)\n",
    "                hf.create_dataset(f'y/{patch_counter}', data=gt_patch)\n",
    "                \n",
    "                # Append patch paths to CSV records\n",
    "                csv_records.append({\n",
    "                    \"path_signal\": f\"{hdf5_filename}/X/{patch_counter}\",\n",
    "                    \"path_target\": f\"{hdf5_filename}/y/{patch_counter}\"\n",
    "                })\n",
    "                \n",
    "                patch_counter += 1  # Increment the patch counter only for valid patches\n",
    "    \n",
    "    # Save the paths to a CSV file if csv_output is True\n",
    "    if csv_output:\n",
    "        csv_df = pd.DataFrame(csv_records)\n",
    "        \n",
    "        if train_test_split_ratio is not None and 0 < train_test_split_ratio < 1:\n",
    "            # Split data into train and test sets\n",
    "            train_df, test_df = train_test_split(csv_df, train_size=train_test_split_ratio, random_state=42)\n",
    "            \n",
    "            # Save train and test CSVs\n",
    "            train_csv_path = os.path.join(output_folder, \"train_patches.csv\")\n",
    "            test_csv_path = os.path.join(output_folder, \"test_patches.csv\")\n",
    "            train_df.to_csv(train_csv_path, index=False)\n",
    "            test_df.to_csv(test_csv_path, index=False)\n",
    "            print(f\"CSV files saved to: {train_csv_path} and {test_csv_path}\")\n",
    "        \n",
    "        else:\n",
    "            # Save a single CSV file\n",
    "            csv_path = os.path.join(output_folder, \"all_patches.csv\")\n",
    "            csv_df.to_csv(csv_path, index=False)\n",
    "            print(f\"CSV file saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracting patches, `save_patches_grid` saves them in a grid format, facilitating visualization and inspection of the patches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 2/2 [00:00<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files saved to: ./_test/train_patches.csv and ./_test/test_patches.csv\n"
     ]
    }
   ],
   "source": [
    "data_folder = './data_examples/Confocal_BPAE_B'\n",
    "# For the sake of simplicity, in this example we use the same folder for ground truth\n",
    "gt_folder = './data_examples/Confocal_BPAE_B' \n",
    "output_folder = './_test'\n",
    "patch_size = (64,64)\n",
    "overlap = 0\n",
    "save_patches_grid(data_folder, gt_folder, output_folder, patch_size, overlap, squeeze_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioMONAI.io import hdf5_reader, split_hdf_path\n",
    "from bioMONAI.visualize import plot_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = './_test/HV110_P0500510000.h5/X/1'\n",
    "\n",
    "im , _ = hdf5_reader()(file_path)\n",
    "plot_image(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_random_patches(data, # numpy array of the input data (n-dimensional).\n",
    "                           patch_size, # tuple of integers defining the size of the patches in each dimension.\n",
    "                           num_patches, # number of random patches to extract.\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    Extracts a specified number of random n-dimensional patches from the input data.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of randomly cropped patches as numpy arrays.\n",
    "    \"\"\"\n",
    "    data_shape = data.shape\n",
    "    ndim = len(data_shape)\n",
    "    \n",
    "    # Ensure patch size fits within the data dimensions\n",
    "    for dim in range(ndim):\n",
    "        if patch_size[dim] > data_shape[dim]:\n",
    "            raise ValueError(f\"Patch size {patch_size[dim]} exceeds data dimension {data_shape[dim]} in dimension {dim}\")\n",
    "    \n",
    "    patches = []\n",
    "    \n",
    "    for _ in range(num_patches):\n",
    "        # Randomly select the starting point for each dimension\n",
    "        start_coords = [random.randint(0, data_shape[dim] - patch_size[dim]) for dim in range(ndim)]\n",
    "        \n",
    "        # Create slices for the selected patch\n",
    "        patch_slices = tuple(slice(start_coords[dim], start_coords[dim] + patch_size[dim]) for dim in range(ndim))\n",
    "        \n",
    "        # Extract the patch and add to the list\n",
    "        patches.append(data[patch_slices])\n",
    "    \n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_patches_random(data_folder,                # Path to the folder containing data files (n-dimensional data).\n",
    "                        gt_folder,                  # Path to the folder containing ground truth (gt) files (n-dimensional data).\n",
    "                        output_folder,              # Path to the folder where the HDF5 files will be saved.\n",
    "                        patch_size,                 # tuple of integers defining the size of the patches.\n",
    "                        num_patches,                # number of random patches to extract per file.\n",
    "                        threshold=None,             # If provided, patches with a mean value below this threshold will be discarded.\n",
    "                        squeeze_input=True,         # If True, squeezes singleton dimensions in the input data.\n",
    "                        squeeze_patches=False,      # If True, squeezes singleton dimensions in the patches.\n",
    "                        csv_output=True,            # If True, a CSV file listing all patch paths is created.\n",
    "                        train_test_split_ratio=0.8, # Ratio of data to split into train and test CSV files (e.g., 0.8 for 80% train).\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Loads n-dimensional data from data_folder and gt_folder, generates random patches, and saves them into individual HDF5 files.\n",
    "    Each HDF5 file will have datasets with the structure X/patch_idx and y/patch_idx.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Ensure the folders contain the same number of files\n",
    "    data_files = sorted([f for f in os.listdir(data_folder) if f.endswith(('.npy', '.npz', '.png', '.tif', '.tiff'))])\n",
    "    gt_files = sorted([f for f in os.listdir(gt_folder) if f.endswith(('.npy', '.npz', '.png', '.tif', '.tiff'))])\n",
    "    \n",
    "    if len(data_files) != len(gt_files):\n",
    "        raise ValueError(\"The number of files in data_folder and gt_folder must be the same.\")\n",
    "    \n",
    "    # Prepare CSV records list\n",
    "    csv_records = []\n",
    "    \n",
    "    # Loop through the files in the folders with progress bar\n",
    "    for data_file_name, gt_file_name in tqdm(zip(data_files, gt_files), total=len(data_files), desc=\"Processing files\"):\n",
    "        data_file_path = os.path.join(data_folder, data_file_name)\n",
    "        gt_file_path = os.path.join(gt_folder, gt_file_name)\n",
    "        \n",
    "        # Load the images\n",
    "        data = np.array(image_reader(data_file_path))\n",
    "        gt = np.array(image_reader(gt_file_path))  \n",
    "        \n",
    "        if squeeze_input:\n",
    "            data = np.squeeze(data)\n",
    "            gt = np.squeeze(gt)\n",
    "                  \n",
    "        if data.shape != gt.shape:\n",
    "            raise ValueError(f\"Shape mismatch between {data_file_name} and {gt_file_name}\")\n",
    "        \n",
    "        # Extract random patches from both datasets\n",
    "        data_patches_nd = extract_random_patches(data, patch_size, num_patches)\n",
    "        gt_patches_nd = extract_random_patches(gt, patch_size, num_patches)\n",
    "        \n",
    "        if squeeze_patches:\n",
    "            data_patches_nd = np.squeeze(data_patches_nd)\n",
    "            gt_patches_nd = np.squeeze(gt_patches_nd)\n",
    "            \n",
    "        # Create a new HDF5 file for this pair of files\n",
    "        hdf5_filename = os.path.join(output_folder, f\"{os.path.splitext(data_file_name)[0]}_random_patches.h5\")\n",
    "        \n",
    "        with h5py.File(hdf5_filename, 'w') as hf:\n",
    "            patch_counter = 0  # Counter to number the valid patches\n",
    "            \n",
    "            # Store each patch in a separate dataset with a progress bar for each file\n",
    "            for data_patch, gt_patch in tqdm(zip(data_patches_nd, gt_patches_nd), \n",
    "                                             total=num_patches, \n",
    "                                             desc=f\"Saving random patches for {data_file_name}\", \n",
    "                                             leave=False):\n",
    "                # Calculate the mean of the patch and discard if below threshold (if provided)\n",
    "                if threshold is not None and np.mean(data_patch) < threshold:\n",
    "                    continue  # Skip this patch\n",
    "                \n",
    "                hf.create_dataset(f'X/{patch_counter}', data=data_patch)\n",
    "                hf.create_dataset(f'y/{patch_counter}', data=gt_patch)\n",
    "                \n",
    "                # Append patch paths to CSV records\n",
    "                csv_records.append({\n",
    "                    \"path_signal\": f\"{hdf5_filename}/X/{patch_counter}\",\n",
    "                    \"path_target\": f\"{hdf5_filename}/y/{patch_counter}\"\n",
    "                })\n",
    "                \n",
    "                patch_counter += 1  # Increment the patch counter only for valid patches\n",
    "    \n",
    "    # Save the paths to a CSV file if csv_output is True\n",
    "    if csv_output:\n",
    "        csv_df = pd.DataFrame(csv_records)\n",
    "        \n",
    "        if train_test_split_ratio is not None and 0 < train_test_split_ratio < 1:\n",
    "            # Split data into train and test sets\n",
    "            train_df, test_df = train_test_split(csv_df, train_size=train_test_split_ratio, random_state=42)\n",
    "            \n",
    "            # Save train and test CSVs\n",
    "            train_csv_path = os.path.join(output_folder, \"train_patches.csv\")\n",
    "            test_csv_path = os.path.join(output_folder, \"test_patches.csv\")\n",
    "            train_df.to_csv(train_csv_path, index=False)\n",
    "            test_df.to_csv(test_csv_path, index=False)\n",
    "            print(f\"CSV files saved to: {train_csv_path} and {test_csv_path}\")\n",
    "        \n",
    "        else:\n",
    "            # Save a single CSV file\n",
    "            csv_path = os.path.join(output_folder, \"all_patches.csv\")\n",
    "            csv_df.to_csv(csv_path, index=False)\n",
    "            print(f\"CSV file saved to: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 2/2 [00:00<00:00, 54.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files saved to: ./_test2/train_patches.csv and ./_test2/test_patches.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_folder = './data_examples/Confocal_BPAE_B' \n",
    "gt_folder = './data_examples/Confocal_BPAE_B' \n",
    "output_folder = './_test2'\n",
    "patch_size = (64,64)\n",
    "num_patches= 2\n",
    "save_patches_random(data_folder, gt_folder, output_folder, patch_size, num_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = './_test2/HV110_P0500510000_random_patches.h5/X/1'\n",
    "\n",
    "im , _ = hdf5_reader()(file_path)\n",
    "plot_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dict2string(d, # The dictionary to convert.\n",
    "                item_sep=\"_\", # The separator between dictionary items (default is \", \").\n",
    "                key_value_sep=\"\", # The separator between keys and values (default is \": \").\n",
    "                pad_zeroes=None, # The minimum width for integer values, padded with zeros. If None, no padding is applied.\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Transforms a dictionary into a string with customizable separators and optional zero padding for integers.\n",
    "\n",
    "    Returns the formatted dictionary as a string.\n",
    "    \"\"\"\n",
    "    def format_value(value):\n",
    "        if isinstance(value, int) and pad_zeroes is not None:\n",
    "            return f\"{value:0{pad_zeroes}d}\"\n",
    "        return str(value)\n",
    "    \n",
    "    return item_sep.join(f\"{k}{key_value_sep}{format_value(v)}\" for k, v in d.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C002_Z030_S001\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'C': 2, 'Z': 30, 'S': 1}\n",
    "result = dict2string(my_dict, pad_zeroes=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_singleton_dims(substack, # The extracted substack data.\n",
    "                          order, # The dimension order string (e.g., 'CZYX').\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    Remove dimensions with a size of 1 from both the substack and the order string.\n",
    "\n",
    "    Returns: \\n\n",
    "        substack (np.array): The substack with singleton dimensions removed.\n",
    "        new_order (str): The updated dimension order string.\n",
    "    \"\"\"\n",
    "    new_order = \"\"\n",
    "    new_shape = []\n",
    "    \n",
    "    for i, dim in enumerate(order):\n",
    "        if substack.shape[i] > 1:  # Keep only dimensions with more than 1 slice\n",
    "            new_order += dim\n",
    "            new_shape.append(substack.shape[i])\n",
    "    \n",
    "    substack = substack.reshape(new_shape)  # Remove singleton dimensions\n",
    "    return substack, new_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_substacks(input_file, # Path to the input OME-TIFF file.\n",
    "                      output_dir=None, # Directory to save the extracted substacks. If a list, the substacks will be saved in the corresponding subdirectories from the list.\n",
    "                      indices=None,# A dictionary specifying which indices to extract. Keys can include 'C' for channel, 'Z' for z-slice, 'T' for time point, and 'S' for scene. If None, all indices are extracted.\n",
    "                      split_dimension=None,# Dimension to split substacks along. If provided, separate substacks will be generated for each index in the split_dimension. Must be one of the keys in indices.\n",
    "                      squeeze_dims=True, # Dimension to squeeze substacks along. \n",
    "                      *kwargs):\n",
    "    \"\"\"\n",
    "    Extract substacks from a multidimensional OME-TIFF stack using AICSImageIO.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load the OME-TIFF file\n",
    "    image = AICSImage(input_file)\n",
    "\n",
    "    # Extract the base name of the input file (without path and extension)\n",
    "    base_filename = os.path.splitext(os.path.basename(input_file))[0]   \n",
    "    # Remove complex extensions like .ome.tiff or .ome.tif\n",
    "    base_filename = os.path.splitext(base_filename)[0]\n",
    "    \n",
    "    # Get dimensions order\n",
    "    order = image.dims.order\n",
    "\n",
    "    # Update defaults with user-specified indices\n",
    "    if indices is None:\n",
    "        indices = dict()\n",
    "        \n",
    "    # Convert any numpy.int types in indices to Python int\n",
    "    indices = {k: int(v) if isinstance(v, (np.integer, np.int64)) else v for k, v in indices.items()}\n",
    "\n",
    "    # If split_dimension is provided, create substacks for each index in that dimension\n",
    "    if split_dimension is not None and split_dimension in indices:\n",
    "        # Extract the dimension indices from the input data\n",
    "        split_indices = indices[split_dimension]\n",
    "        if isinstance(split_indices, int):\n",
    "            split_indices = [split_indices]  # Ensure it's a list even if a single index is passed\n",
    "\n",
    "        # Ensure output_dir is a list of directories or convert to list of subfolder names by index\n",
    "        if output_dir is not None and isinstance(output_dir, list):\n",
    "            if len(output_dir) != len(split_indices):\n",
    "                if len(output_dir) == 1:\n",
    "                    output_dir_list = [os.path.join(output_dir[0], f\"{split_dimension}_{i}\") for i in split_indices]\n",
    "                else:\n",
    "                    raise ValueError(f\"The number of subdirectories in output_dir ({len(output_dir)}) does not match the number of substacks ({len(split_indices)}).\")\n",
    "            else:\n",
    "                output_dir_list = output_dir\n",
    "        elif output_dir is not None:\n",
    "            output_dir_list = [output_dir] * len(split_indices)\n",
    "        else:\n",
    "            output_dir_list = [None] * len(split_indices)  # No output_dir provided, substack is returned.\n",
    "\n",
    "        # Loop through indices in the split dimension\n",
    "        for i, idx in enumerate(split_indices):\n",
    "            # Adjust the indices dictionary for the current index in split_dimension\n",
    "            current_indices = indices.copy()\n",
    "            current_indices[split_dimension] = int(idx) \n",
    "            \n",
    "            # Extract the substack for the current index\n",
    "            substack = image.get_image_data(order, **current_indices)\n",
    "            \n",
    "            # Remove singleton dimensions\n",
    "            if squeeze_dims:\n",
    "                substack, new_order = remove_singleton_dims(substack, order)\n",
    "            else:\n",
    "                new_order = order\n",
    "\n",
    "            # Save the substack\n",
    "            if output_dir is None:\n",
    "                return substack  # Return the first substack if no output_dir is specified\n",
    "            \n",
    "            # Ensure the specific subfolder exists\n",
    "            os.makedirs(output_dir_list[i], exist_ok=True)\n",
    "            \n",
    "            # Construct output filename\n",
    "            output_filename = f\"{base_filename}_substack_{dict2string(current_indices, *kwargs)}.ome.tiff\"\n",
    "            output_path = os.path.join(output_dir_list[i], output_filename)\n",
    "\n",
    "            # Save the substack\n",
    "            OmeTiffWriter.save(substack, output_path, dim_order=new_order)\n",
    "\n",
    "            print(f\"Extracted substack saved to: {output_path}\")\n",
    "    \n",
    "    else:\n",
    "        # No split_dimension provided, extract the entire substack\n",
    "        substack = image.get_image_data(order, **indices)\n",
    "        \n",
    "        # Remove singleton dimensions\n",
    "        if squeeze_dims:\n",
    "            substack, new_order = remove_singleton_dims(substack, order)\n",
    "        else:\n",
    "            new_order = order\n",
    "\n",
    "        if output_dir is None:\n",
    "            return substack  # Return substack if no output_dir is provided\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Construct output filename\n",
    "        output_filename = f\"{base_filename}_substack_{dict2string(indices, *kwargs)}.ome.tiff\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        # Save the substack\n",
    "        OmeTiffWriter.save(substack, output_path, dim_order=new_order)\n",
    "\n",
    "        print(f\"Extracted substack saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./_test_folder/channel_0',\n",
       " './_test_folder/channel_1',\n",
       " './_test_folder/channel_2']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./_test_folder/\"\n",
    "subdirs = [output_dir + folder for folder in [\"channel_0\", \"channel_1\", \"channel_2\"]]\n",
    "subdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./_test_folder/./_test_folder/channel_0_0',\n",
       " './_test_folder/./_test_folder/channel_0_1']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[os.path.join([output_dir][0], f\"{subdirs[0]}_{ii}\") for ii in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted substack saved to: ./_test_folder/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C0_Zrange(0, 35)_T0.ome.tiff\n"
     ]
    }
   ],
   "source": [
    "filename = './data_examples/2155a4fe_3500000635_100X_20170227_E08_P21.ome.tiff'\n",
    "\n",
    "# This extracts a single substack for channel 0, z-slice 5, and time point 0.\n",
    "extract_substacks(filename, output_dir=output_dir, indices={\"C\": 0, \"Z\": range(35), \"T\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted substack saved to: ./_test_folder/C_0/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C0_Z5_T0.ome.tiff\n",
      "Extracted substack saved to: ./_test_folder/C_1/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C1_Z5_T0.ome.tiff\n",
      "Extracted substack saved to: ./_test_folder/C_2/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C2_Z5_T0.ome.tiff\n"
     ]
    }
   ],
   "source": [
    "# This extracts substacks for each channel (`C`) and saves them in separate subfolders named \"C_0\", \"C_1\", \"C_2\", etc.\n",
    "extract_substacks(filename, output_dir=[output_dir], indices={\"C\": [0, 1, 2], \"Z\": 5, \"T\": 0}, split_dimension=\"C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted substack saved to: ./_test_folder/channel_0/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C0_Z5.ome.tiff\n",
      "Extracted substack saved to: ./_test_folder/channel_1/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C1_Z5.ome.tiff\n",
      "Extracted substack saved to: ./_test_folder/channel_2/2155a4fe_3500000635_100X_20170227_E08_P21_substack_C2_Z5.ome.tiff\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This extracts substacks for each channel and saves them in directories \"channel_0\", \"channel_1\", and \"channel_2\".\n",
    "extract_substacks(filename, output_dir=subdirs, indices={\"C\": [0, 1, 2], \"Z\": 5}, split_dimension=\"C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
